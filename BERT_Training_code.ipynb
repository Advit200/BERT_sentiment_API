{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2021-08-18T11:03:09.301036Z","iopub.status.busy":"2021-08-18T11:03:09.300642Z","iopub.status.idle":"2021-08-18T11:03:09.320903Z","shell.execute_reply":"2021-08-18T11:03:09.319932Z","shell.execute_reply.started":"2021-08-18T11:03:09.300954Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/finaldata/Final_PowerBI_input.xlsx\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"markdown","metadata":{},"source":["**BERT Notes :**\n","\n","1. BERT is transformer based model which is different from LLSTM model in the sense,text doesnt have to put in a sequence in BERT compared to LSTM models.So it is fast as a whole sentence can be splitted into words and put at once i.e parallel processing of the words are possible.Even though the words are put at once,BERT has the ability to catch the sequence btw the words and the context in which it is being used in the sentence.This also solves one of the problem with the LSTM models where when the sentences become very long,there are chances of the LSTM model to loose the context and effect of one word on other words.This is solved in BERT model by assigning position to each of the words of the sentence before inserting into the attention layers and is achieved by the \"positional encoding\" layer.\n","\n","2. BERT is also different from other DL models in the sense that it generates \"contextual embeddings\" i.e a word has different vector representation depending on the contect in which is used.This is lacked by the word2vec or glove models.\n","\n","3. BERT is basically trained for two tasks : First for masked language modelling ( masking 15 % of the words in the corpus and then asking the NN to preddict those words ) and second for next sentence prediction ( given two sentences,predicte that if the next sentence is continuation/follow of the previous sentence.\n","\n","4. BERT can be very easily fine tuned for the specifics NLP tasks like sentiment analysis,question answering etc.It has million of parameters,so even fine tunning the BERT model for 1-2 epochs enchanes the performace a lot.\n","\n","5. BERT has a non-directional artitecture compared to bidirectional or single in LSTMs."]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:03:09.332392Z","iopub.status.busy":"2021-08-18T11:03:09.331906Z","iopub.status.idle":"2021-08-18T11:03:11.576210Z","shell.execute_reply":"2021-08-18T11:03:11.575225Z","shell.execute_reply.started":"2021-08-18T11:03:09.332355Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import transformers\n","import torch\n","from torch.utils import data\n","from torch import nn,optim\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils import shuffle\n","from sklearn.metrics import accuracy_score,matthews_corrcoef,confusion_matrix,classification_report,roc_auc_score\n","from collections import defaultdict\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from torch.utils.data import WeightedRandomSampler"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:03:11.578389Z","iopub.status.busy":"2021-08-18T11:03:11.577989Z","iopub.status.idle":"2021-08-18T11:03:11.641647Z","shell.execute_reply":"2021-08-18T11:03:11.640657Z","shell.execute_reply.started":"2021-08-18T11:03:11.578346Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla P100-PCIE-16GB\n"]}],"source":["import torch\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:03:11.644706Z","iopub.status.busy":"2021-08-18T11:03:11.643859Z","iopub.status.idle":"2021-08-18T11:03:21.143313Z","shell.execute_reply":"2021-08-18T11:03:21.142373Z","shell.execute_reply.started":"2021-08-18T11:03:11.644648Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting openpyxl\n","  Downloading openpyxl-3.0.7-py2.py3-none-any.whl (243 kB)\n","\u001b[K     |████████████████████████████████| 243 kB 824 kB/s eta 0:00:01     |███████████████████████████████ | 235 kB 824 kB/s eta 0:00:01\n","\u001b[?25hCollecting nlpaug\n","  Downloading nlpaug-1.1.7-py3-none-any.whl (405 kB)\n","\u001b[K     |████████████████████████████████| 405 kB 4.6 MB/s eta 0:00:01\n","\u001b[?25hCollecting et-xmlfile\n","  Downloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n","Installing collected packages: et-xmlfile, openpyxl, nlpaug\n","Successfully installed et-xmlfile-1.1.0 nlpaug-1.1.7 openpyxl-3.0.7\n","\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"]}],"source":["! pip install openpyxl nlpaug"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:03:21.145707Z","iopub.status.busy":"2021-08-18T11:03:21.145257Z","iopub.status.idle":"2021-08-18T11:03:29.762023Z","shell.execute_reply":"2021-08-18T11:03:29.761213Z","shell.execute_reply.started":"2021-08-18T11:03:21.145656Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Rating</th>\n","      <th>Pros</th>\n","      <th>Cons</th>\n","      <th>Main_Review</th>\n","      <th>Review_id</th>\n","      <th>Sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1. This company has eight hours shift round th...</td>\n","      <td>1</td>\n","      <td>POSITIVE</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>As with all jobs, your experience will depend ...</td>\n","      <td>2</td>\n","      <td>POSITIVE</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5</td>\n","      <td>Good benefits</td>\n","      <td>Work your life away</td>\n","      <td>Very hot and dirty working conditions very old...</td>\n","      <td>3</td>\n","      <td>NEUTRAL</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>5</td>\n","      <td>Full benefits, good pay, mist fans</td>\n","      <td>The Texas heat</td>\n","      <td>Everyone is pretty helpful there especially be...</td>\n","      <td>4</td>\n","      <td>POSITIVE</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>5</td>\n","      <td>Benefits</td>\n","      <td>Oil related</td>\n","      <td>Rewarding place to work. Everyone is professio...</td>\n","      <td>5</td>\n","      <td>POSITIVE</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>21561</th>\n","      <td>4</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>10884</td>\n","      <td>POSITIVE</td>\n","    </tr>\n","    <tr>\n","      <th>21562</th>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>10885</td>\n","      <td>NEGATIVE</td>\n","    </tr>\n","    <tr>\n","      <th>21563</th>\n","      <td>4</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>10886</td>\n","      <td>POSITIVE</td>\n","    </tr>\n","    <tr>\n","      <th>21564</th>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>10887</td>\n","      <td>POSITIVE</td>\n","    </tr>\n","    <tr>\n","      <th>21565</th>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>10888</td>\n","      <td>POSITIVE</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10888 rows × 6 columns</p>\n","</div>"],"text/plain":["       Rating                                Pros                 Cons  \\\n","0           4                                 NaN                  NaN   \n","2           4                                 NaN                  NaN   \n","5           5                       Good benefits  Work your life away   \n","7           5  Full benefits, good pay, mist fans       The Texas heat   \n","10          5                            Benefits          Oil related   \n","...       ...                                 ...                  ...   \n","21561       4                                 NaN                  NaN   \n","21562       1                                 NaN                  NaN   \n","21563       4                                 NaN                  NaN   \n","21564       3                                 NaN                  NaN   \n","21565       3                                 NaN                  NaN   \n","\n","                                             Main_Review  Review_id Sentiment  \n","0      1. This company has eight hours shift round th...          1  POSITIVE  \n","2      As with all jobs, your experience will depend ...          2  POSITIVE  \n","5      Very hot and dirty working conditions very old...          3   NEUTRAL  \n","7      Everyone is pretty helpful there especially be...          4  POSITIVE  \n","10     Rewarding place to work. Everyone is professio...          5  POSITIVE  \n","...                                                  ...        ...       ...  \n","21561                                                NaN      10884  POSITIVE  \n","21562                                                NaN      10885  NEGATIVE  \n","21563                                                NaN      10886  POSITIVE  \n","21564                                                NaN      10887  POSITIVE  \n","21565                                                NaN      10888  POSITIVE  \n","\n","[10888 rows x 6 columns]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_excel(\"../input/finaldata/Final_PowerBI_input.xlsx\",usecols=[\"Rating\",\"Main_Review\",\"Pros\",\"Cons\",\"Sentiment\",\"Review_id\"],engine=\"openpyxl\")\n","df.drop_duplicates(inplace=True)\n","df"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:03:29.763531Z","iopub.status.busy":"2021-08-18T11:03:29.763198Z","iopub.status.idle":"2021-08-18T11:03:29.944912Z","shell.execute_reply":"2021-08-18T11:03:29.943974Z","shell.execute_reply.started":"2021-08-18T11:03:29.763504Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<AxesSubplot:>"]},"execution_count":6,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["df.Rating.value_counts().plot(kind=\"bar\")"]},{"cell_type":"markdown","metadata":{},"source":["**{0:\"NEGATIVE\",\n","   1:\"NEUTRAL\",\n","   2:\"POSITIVE\"}**"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:03:29.946876Z","iopub.status.busy":"2021-08-18T11:03:29.946524Z","iopub.status.idle":"2021-08-18T11:03:30.445387Z","shell.execute_reply":"2021-08-18T11:03:30.444600Z","shell.execute_reply.started":"2021-08-18T11:03:29.946838Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>Review</th>\n","      <th>Actual_Sentiment</th>\n","      <th>Review_id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1. This company has eight hours shift round th...</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>As with all jobs, your experience will depend ...</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>Very hot and dirty working conditions very old...</td>\n","      <td>2</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>Everyone is pretty helpful there especially be...</td>\n","      <td>2</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>Rewarding place to work. Everyone is professio...</td>\n","      <td>2</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>21688</th>\n","      <td>21688</td>\n","      <td>Not much of work at the start</td>\n","      <td>0</td>\n","      <td>10858</td>\n","    </tr>\n","    <tr>\n","      <th>21689</th>\n","      <td>21689</td>\n","      <td>its a captive company but work wise worst then...</td>\n","      <td>0</td>\n","      <td>10859</td>\n","    </tr>\n","    <tr>\n","      <th>21690</th>\n","      <td>21690</td>\n","      <td>None whatsoever</td>\n","      <td>0</td>\n","      <td>10860</td>\n","    </tr>\n","    <tr>\n","      <th>21691</th>\n","      <td>21691</td>\n","      <td>Poor management</td>\n","      <td>0</td>\n","      <td>10862</td>\n","    </tr>\n","    <tr>\n","      <th>21692</th>\n","      <td>21692</td>\n","      <td>No</td>\n","      <td>0</td>\n","      <td>10863</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>21693 rows × 4 columns</p>\n","</div>"],"text/plain":["       index                                             Review  \\\n","0          0  1. This company has eight hours shift round th...   \n","1          1  As with all jobs, your experience will depend ...   \n","2          2  Very hot and dirty working conditions very old...   \n","3          3  Everyone is pretty helpful there especially be...   \n","4          4  Rewarding place to work. Everyone is professio...   \n","...      ...                                                ...   \n","21688  21688                      Not much of work at the start   \n","21689  21689  its a captive company but work wise worst then...   \n","21690  21690                                    None whatsoever   \n","21691  21691                                    Poor management   \n","21692  21692                                                 No   \n","\n","       Actual_Sentiment  Review_id  \n","0                     2          1  \n","1                     2          2  \n","2                     2          3  \n","3                     2          4  \n","4                     2          5  \n","...                 ...        ...  \n","21688                 0      10858  \n","21689                 0      10859  \n","21690                 0      10860  \n","21691                 0      10862  \n","21692                 0      10863  \n","\n","[21693 rows x 4 columns]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["## For \"Main_Review\" column, assigning review based on \"Rating' column\n","\n","temp_df = df.copy()\n","temp_df[\"Actual_Sentiment\"] = temp_df.loc[:,\"Rating\"].apply(lambda x : 0 if x <= 2 else 1 if x == 3 else 2)\n","temp_df[\"Review\"] = temp_df[\"Main_Review\"].str.replace(r\"'|\\\"|\\\"|'|!|\\s+\", \" \",regex=True)\n","temp_df.dropna(subset=[\"Review\"],inplace=True)\n","\n","temp_df = temp_df[[\"Review\",\"Actual_Sentiment\",\"Review_id\"]]\n","temp_df\n","\n","######################################################################\n","## Assigning POSITIVE sentiment to all the reviews in \"Pros\" category.\n","\n","temp_df_1 = df.copy()\n","temp_df_1[\"Actual_Sentiment\"] = 2\n","temp_df_1[\"Review\"] = temp_df_1[\"Pros\"].str.replace(r\"'|\\\"|\\\"|'|!|\\s+\", \" \",regex=True)\n","temp_df_1.dropna(subset=[\"Review\"],inplace=True)\n","\n","temp_df_pros = temp_df_1[[\"Review\",\"Actual_Sentiment\",\"Review_id\"]]\n","temp_df_pros\n","\n","######################################################################\n","## Assigning NEGATIVE sentiment to all the reviews in \"Cons\" category.\n","\n","temp_df_2 = df.copy()\n","temp_df_2[\"Actual_Sentiment\"] = 0\n","temp_df_2[\"Review\"] = temp_df_2[\"Cons\"].str.replace(r\"'|\\\"|\\\"|'|!|\\s+\", \" \",regex=True)\n","temp_df_2.dropna(subset=[\"Review\"],inplace=True)\n","\n","temp_df_cons = temp_df_2[[\"Review\",\"Actual_Sentiment\",\"Review_id\"]]\n","temp_df_cons\n","\n","######################################################################\n","\n","final_df = pd.concat([temp_df,temp_df_pros,temp_df_cons],axis=0,ignore_index=True)\n","final_df.reset_index(inplace=True)\n","final_df"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:03:30.447106Z","iopub.status.busy":"2021-08-18T11:03:30.446770Z","iopub.status.idle":"2021-08-18T11:03:30.682147Z","shell.execute_reply":"2021-08-18T11:03:30.681008Z","shell.execute_reply.started":"2021-08-18T11:03:30.447070Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<AxesSubplot:ylabel='Frequency'>"]},"execution_count":8,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["final_df[\"Review_len\"] = final_df[\"Review\"].apply(lambda x : len(x.split()))\n","final_df[\"Review_len\"].plot(kind=\"hist\",xlim=(0,200))\n","\n","# This shows that most of the reviews have less than 100 words in it ."]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:03:30.685856Z","iopub.status.busy":"2021-08-18T11:03:30.685420Z","iopub.status.idle":"2021-08-18T11:03:30.701395Z","shell.execute_reply":"2021-08-18T11:03:30.700430Z","shell.execute_reply.started":"2021-08-18T11:03:30.685811Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(20808, 5)"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# Dropping data that has only one word in review\n","\n","drop_index = final_df.query('Review_len <=1').index\n","\n","final_df = final_df.loc[~final_df.index.isin(drop_index) , :]\n","\n","final_df.shape"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:03:30.704223Z","iopub.status.busy":"2021-08-18T11:03:30.703660Z","iopub.status.idle":"2021-08-18T11:03:30.830897Z","shell.execute_reply":"2021-08-18T11:03:30.829938Z","shell.execute_reply.started":"2021-08-18T11:03:30.704185Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["2    10647\n","0     8714\n","1     1447\n","Name: Actual_Sentiment, dtype: int64\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["final_df[\"Actual_Sentiment\"].value_counts().plot(kind=\"bar\")\n","\n","print(final_df[\"Actual_Sentiment\"].value_counts())\n","\n","# Neutral sentiment is very less, so need to perform text augmentation "]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:03:30.832655Z","iopub.status.busy":"2021-08-18T11:03:30.832289Z","iopub.status.idle":"2021-08-18T11:03:30.846089Z","shell.execute_reply":"2021-08-18T11:03:30.845025Z","shell.execute_reply.started":"2021-08-18T11:03:30.832615Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>Review</th>\n","      <th>Actual_Sentiment</th>\n","      <th>Review_id</th>\n","      <th>Review_len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>Everyone is pretty helpful there especially be...</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>28</td>\n","    </tr>\n","    <tr>\n","      <th>6298</th>\n","      <td>6298</td>\n","      <td>Full benefits, good pay, mist fans</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>14020</th>\n","      <td>14020</td>\n","      <td>The Texas heat</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       index                                             Review  \\\n","3          3  Everyone is pretty helpful there especially be...   \n","6298    6298                 Full benefits, good pay, mist fans   \n","14020  14020                                     The Texas heat   \n","\n","       Actual_Sentiment  Review_id  Review_len  \n","3                     2          4          28  \n","6298                  2          4           6  \n","14020                 0          4           3  "]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["final_df.loc[final_df[\"Review_id\"]==4,:]"]},{"cell_type":"markdown","metadata":{},"source":["## Augmenting the Neutral Reviews as their count is less"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:03:30.847953Z","iopub.status.busy":"2021-08-18T11:03:30.847588Z","iopub.status.idle":"2021-08-18T11:03:31.044168Z","shell.execute_reply":"2021-08-18T11:03:31.043175Z","shell.execute_reply.started":"2021-08-18T11:03:30.847906Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<AxesSubplot:ylabel='Frequency'>"]},"execution_count":12,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAY4AAAD4CAYAAAD7CAEUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAVFElEQVR4nO3dfbBc9X3f8ffHyDY2wYgHRdVIEEGi4DKTGORrh0xs1zFxYoSNSJoQqBtUqonSKemYSTOxbGcSOpPO4LYxMWmKqxg3gtjGYIeiFpIaK7YznSlgATLPFEFQkSzQNbbBMQ4E59s/9nfJIvSw5+oe7V7zfs3s7O9895xzv5y77EfnYc9NVSFJ0qheMe4GJEnzi8EhSerE4JAkdWJwSJI6MTgkSZ0sGHcDB+O4446r5cuXj7sNSZpXbr/99q9X1aLZLj+vg2P58uVs2bJl3G1I0rySZPvBLO+hKklSJwaHJKkTg0OS1InBIUnqxOCQJHVicEiSOjE4JEmd9BYcSU5OsnXo8XSSi5Mck+TmJA+156Pb/ElyeZJtSe5KsrKv3iRJs9dbcFTVg1V1alWdCrwReAa4HlgPbK6qFcDmNg1wJrCiPdYBV/TVmyRp9g7VN8fPAB6uqu1JVgNvb/WNwJeA9wOrgatq8JelbkmyMMmSqto1mx+4fP2NB9/1hHj00rPG3YIkveBQneM4D/h0Gy8eCoPHgcVtvBR4bGiZHa32IknWJdmSZMv09HRf/UqS9qH34EjyKuBs4Lo9X2t7F53+dm1VbaiqqaqaWrRo1vfokiTN0qHY4zgTuKOqnmjTTyRZAtCed7f6TuD4oeWWtZokaYIciuA4n384TAWwCVjTxmuAG4bqF7Srq04Hnprt+Q1JUn96PTme5AjgncCvDZUvBa5NshbYDpzb6jcBq4BtDK7AurDP3iRJs9NrcFTVd4Bj96g9yeAqqz3nLeCiPvuRJB08vzkuSerE4JAkdWJwSJI6MTgkSZ0YHJKkTgwOSVInBockqRODQ5LUicEhSerE4JAkdWJwSJI6MTgkSZ0YHJKkTgwOSVInBockqRODQ5LUicEhSerE4JAkdWJwSJI6MTgkSZ30GhxJFib5bJIHktyf5CeTHJPk5iQPteej27xJcnmSbUnuSrKyz94kSbPT9x7HR4G/qKrXA28A7gfWA5uragWwuU0DnAmsaI91wBU99yZJmoXegiPJUcDbgCsBquq5qvoWsBrY2GbbCJzTxquBq2rgFmBhkiV99SdJmp0+9zhOBKaB/5bkziQfT3IEsLiqdrV5HgcWt/FS4LGh5Xe0miRpgvQZHAuAlcAVVXUa8B3+4bAUAFVVQHVZaZJ1SbYk2TI9PT1nzUqSRtNncOwAdlTVrW36swyC5ImZQ1DteXd7fSdw/NDyy1rtRapqQ1VNVdXUokWLemtekrR3vQVHVT0OPJbk5FY6A7gP2ASsabU1wA1tvAm4oF1ddTrw1NAhLUnShFjQ8/r/DfDJJK8CHgEuZBBW1yZZC2wHzm3z3gSsArYBz7R5JUkTptfgqKqtwNReXjpjL/MWcFGf/UiSDp7fHJckdWJwSJI6MTgkSZ0YHJKkTgwOSVInBockqRODQ5LUicEhSerE4JAkdWJwSJI6MTgkSZ0YHJKkTgwOSVInBockqRODQ5LUicEhSerE4JAkdWJwSJI6MTgkSZ0YHJKkTgwOSVInvQZHkkeT3J1ka5ItrXZMkpuTPNSej271JLk8ybYkdyVZ2WdvkqTZORR7HD9dVadW1VSbXg9srqoVwOY2DXAmsKI91gFXHILeJEkdjeNQ1WpgYxtvBM4Zql9VA7cAC5MsGUN/kqT96Ds4Cvh8ktuTrGu1xVW1q40fBxa38VLgsaFld7TaiyRZl2RLki3T09N99S1J2ocFPa//LVW1M8kPAjcneWD4xaqqJNVlhVW1AdgAMDU11WnZ+Wr5+hvH3cKcefTSs8bdgqSD1OseR1XtbM+7geuBNwNPzByCas+72+w7geOHFl/WapKkCdJbcCQ5IsmRM2PgZ4F7gE3AmjbbGuCGNt4EXNCurjodeGrokJYkaUL0eahqMXB9kpmf86mq+oskXwGuTbIW2A6c2+a/CVgFbAOeAS7ssTdJ0iz1FhxV9Qjwhr3UnwTO2Eu9gIv66keSNDf85rgkqRODQ5LUicEhSerE4JAkdWJwSJI6MTgkSZ0YHJKkTgwOSVInBockqZORgiPJj/XdiCRpfhh1j+O/JLktyb9OclSvHUmSJtpIwVFVbwXey+C257cn+VSSd/bamSRpIo18jqOqHgJ+G3g/8E+Ay5M8kOQX+mpOkjR5Rj3H8eNJLgPuB94BvKeq/nEbX9Zjf5KkCTPqbdX/EPg48MGq+u5Msaq+luS3e+lMkjSRRg2Os4DvVtX3AJK8Aji8qp6pqqt7606SNHFGPcfxBeA1Q9OvbTVJ0svMqMFxeFX9zcxEG7+2n5YkSZNs1OD4TpKVMxNJ3gh8dz/zS5K+T416juNi4LokXwMC/CPgl/tqSpI0uUYKjqr6SpLXAye30oNV9XejLJvkMGALsLOq3p3kROAa4FjgduBXquq5JK8GrgLeCDwJ/HJVPdrpv0aS1LsuNzl8E/DjwErg/CQXjLjc+xh8/2PGh4HLqupHgG8Ca1t9LfDNVr+szSdJmjCjfgHwauA/AW9hECBvAqZGWG4Zg0t5P96mw+BLg59ts2wEzmnj1W2a9voZbX5J0gQZ9RzHFHBKVVXH9f8B8FvAkW36WOBbVfV8m94BLG3jpcBjAFX1fJKn2vxfH15hknXAOoATTjihYzuSpIM16qGqexicEB9ZkncDu6vq9s5d7UdVbaiqqaqaWrRo0VyuWpI0glH3OI4D7ktyG/DsTLGqzt7PMj8FnJ1kFXA48Drgo8DCJAvaXscyYGebfyeDu+/uSLIAOIrBSXJJ0gQZNTgu6briqvoA8AGAJG8HfrOq3pvkOuAXGVxZtQa4oS2yqU3/n/b6X87i0JgkqWejXo775SQ/BKyoqi8keS1w2Cx/5vuBa5L8HnAncGWrXwlcnWQb8A3gvFmuX5LUo5GCI8mvMjghfQzwwwxOZH8MOGOU5avqS8CX2vgR4M17medvgV8aZX2SpPEZ9eT4RQzOWTwNL/xRpx/sqylJ0uQaNTierarnZibayWvPP0jSy9CowfHlJB8EXtP+1vh1wP/ory1J0qQaNTjWA9PA3cCvATcx+PvjkqSXmVGvqvp74I/bQ5L0MjbqVVV/zV7OaVTVSXPekSRponW5V9WMwxlcNnvM3LcjSZp0I53jqKonhx47q+oPGNz1VpL0MjPqoaqVQ5OvYLAHMureiiTp+8ioH/6/PzR+HngUOHfOu5EkTbxRr6r66b4bkSTND6MeqvqN/b1eVR+Zm3YkSZOuy1VVb2Jw63OA9wC3AQ/10ZQkaXKNGhzLgJVV9W2AJJcAN1bVP++rMUnSZBr1liOLgeeGpp9rNUnSy8yoexxXAbclub5NnwNs7KUjSdJEG/Wqqn+f5M+Bt7bShVV1Z39tSZIm1aiHqgBeCzxdVR8FdiQ5saeeJEkTbKTgSPK7DP5W+Ada6ZXAn/bVlCRpco26x/HzwNnAdwCq6mvAkX01JUmaXKMGx3NVVbRbqyc5or+WJEmTbNTguDbJfwUWJvlV4Asc4I86JTk8yW1Jvprk3iT/rtVPTHJrkm1JPpPkVa3+6ja9rb2+/CD+uyRJPTlgcCQJ8Bngs8DngJOB36mqPzzAos8C76iqNwCnAu9KcjrwYeCyqvoR4JvA2jb/WuCbrX5Zm0+SNGEOeDluVVWSm6rqx4CbR11xO7T1N23yle1RwDuAf9bqG4FLgCuA1W0Mg5D6z0nS1iNJmhCjHqq6I8mbuq48yWFJtgK7GYTOw8C3qur5NssOYGkbLwUeA2ivPwUcu5d1rkuyJcmW6enpri1Jkg7SqMHxE8AtSR5OcleSu5PcdaCFqup7VXUqg3tdvRl4/exbfWGdG6pqqqqmFi1adLCrkyR1tN9DVUlOqKr/B/zcwfyQqvpWki8CP8ngBPuCtlexDNjZZtsJHM/gy4ULgKOAJw/m50qS5t6B9jj+O0BVbQc+UlXbhx/7WzDJoiQL2/g1wDuB+4EvAr/YZlsD3NDGm9o07fW/9PyGJE2eA50cz9D4pI7rXgJsTHIYg4C6tqr+Z5L7gGuS/B5wJ3Blm/9K4Ook24BvAOd1/HmSpEPgQMFR+xgfUFXdBZy2l/ojDM537Fn/W+CXuvwMSdKhd6DgeEOSpxnsebymjWnTVVWv67U7SdLE2W9wVNVhh6oRSdL80OW26pIkGRySpG4MDklSJwaHJKkTg0OS1InBIUnqxOCQJHVicEiSOjE4JEmdGBySpE4MDklSJwaHJKkTg0OS1InBIUnqxOCQJHVicEiSOjE4JEmdGBySpE56C44kxyf5YpL7ktyb5H2tfkySm5M81J6PbvUkuTzJtiR3JVnZV2+SpNnrc4/jeeDfVtUpwOnARUlOAdYDm6tqBbC5TQOcCaxoj3XAFT32Jkmapd6Co6p2VdUdbfxt4H5gKbAa2Nhm2wic08argatq4BZgYZIlffUnSZqdQ3KOI8ly4DTgVmBxVe1qLz0OLG7jpcBjQ4vtaLU917UuyZYkW6anp/trWpK0V70HR5IfAD4HXFxVTw+/VlUFVJf1VdWGqpqqqqlFixbNYaeSpFH0GhxJXskgND5ZVX/Wyk/MHIJqz7tbfSdw/NDiy1pNkjRB+ryqKsCVwP1V9ZGhlzYBa9p4DXDDUP2CdnXV6cBTQ4e0JEkTYkGP6/4p4FeAu5NsbbUPApcC1yZZC2wHzm2v3QSsArYBzwAX9tibJGmWeguOqvrfQPbx8hl7mb+Ai/rqR5I0N/zmuCSpE4NDktSJwSFJ6sTgkCR1YnBIkjoxOCRJnRgckqRODA5JUicGhySpE4NDktSJwSFJ6sTgkCR1YnBIkjrp87bq0kssX3/juFuYE49eeta4W5DGxj0OSVInBockqRODQ5LUicEhSerE4JAkdWJwSJI66S04knwiye4k9wzVjklyc5KH2vPRrZ4klyfZluSuJCv76kuSdHD63OP4E+Bde9TWA5uragWwuU0DnAmsaI91wBU99iVJOgi9BUdV/RXwjT3Kq4GNbbwROGeoflUN3AIsTLKkr94kSbN3qM9xLK6qXW38OLC4jZcCjw3Nt6PVXiLJuiRbkmyZnp7ur1NJ0l6N7eR4VRVQs1huQ1VNVdXUokWLeuhMkrQ/hzo4npg5BNWed7f6TuD4ofmWtZokacIc6uDYBKxp4zXADUP1C9rVVacDTw0d0pIkTZDe7o6b5NPA24HjkuwAfhe4FLg2yVpgO3Bum/0mYBWwDXgGuLCvviRJB6e34Kiq8/fx0hl7mbeAi/rqRZI0d/zmuCSpE4NDktSJwSFJ6sTgkCR1YnBIkjoxOCRJnRgckqRODA5JUie9fQFQ+n62fP2N425hzjx66VnjbkHzjHsckqRODA5JUicGhySpE4NDktSJwSFJ6sTgkCR1YnBIkjoxOCRJnfgFQOllzi8zqiv3OCRJnRgckqROPFQl6fuGh90OjYna40jyriQPJtmWZP24+5EkvdTEBEeSw4A/As4ETgHOT3LKeLuSJO1pkg5VvRnYVlWPACS5BlgN3DfWriRpDCb5sNskBcdS4LGh6R3AT+w5U5J1wLo2+WySew5BbwfrOODr425iBPY5d+ZDj2Cfc22+9HnywSw8ScExkqraAGwASLKlqqbG3NIB2efcmg99zocewT7n2nzq82CWn5hzHMBO4Pih6WWtJkmaIJMUHF8BViQ5McmrgPOATWPuSZK0h4k5VFVVzyf5deB/AYcBn6iqew+w2Ib+O5sT9jm35kOf86FHsM+59rLoM1U1V41Ikl4GJulQlSRpHjA4JEmdzNvgmMTbkyQ5PskXk9yX5N4k72v1S5LsTLK1PVZNQK+PJrm79bOl1Y5JcnOSh9rz0WPu8eShbbY1ydNJLp6E7ZnkE0l2D3+PaF/bLwOXt/fqXUlWjrnP/5jkgdbL9UkWtvryJN8d2q4fG3Of+/w9J/lA254PJvm5Mff5maEeH02ytdXHsj338zk0d+/Pqpp3DwYnzx8GTgJeBXwVOGUC+loCrGzjI4H/y+D2KZcAvznu/vbo9VHguD1q/wFY38brgQ+Pu889fuePAz80CdsTeBuwErjnQNsPWAX8ORDgdODWMff5s8CCNv7wUJ/Lh+ebgO25199z+3/qq8CrgRPbZ8Fh4+pzj9d/H/idcW7P/XwOzdn7c77ucbxwe5Kqeg6YuT3JWFXVrqq6o42/DdzP4Bvx88VqYGMbbwTOGV8rL3EG8HBVbR93IwBV9VfAN/Yo72v7rQauqoFbgIVJloyrz6r6fFU93yZvYfCdqbHax/bcl9XANVX1bFX9NbCNwWdC7/bXZ5IA5wKfPhS97Mt+Pofm7P05X4Njb7cnmagP6CTLgdOAW1vp19tu4CfGfQioKeDzSW7P4DYuAIuralcbPw4sHk9re3UeL/4fctK2J+x7+03y+/VfMvjX5owTk9yZ5MtJ3jqupobs7fc8qdvzrcATVfXQUG2s23OPz6E5e3/O1+CYaEl+APgccHFVPQ1cAfwwcCqwi8Hu7Li9papWMrgb8UVJ3jb8Yg32YSfiWu0MvhB6NnBdK03i9nyRSdp++5LkQ8DzwCdbaRdwQlWdBvwG8KkkrxtXf8yD3/MezufF/7gZ6/bcy+fQCw72/Tlfg2Nib0+S5JUMflmfrKo/A6iqJ6rqe1X198Afc4h2q/enqna2593A9Qx6emJmF7U97x5fhy9yJnBHVT0Bk7k9m31tv4l7vyb5F8C7gfe2DxHaoZ8n2/h2BucOfnRcPe7n9zyJ23MB8AvAZ2Zq49yee/scYg7fn/M1OCby9iTtGOeVwP1V9ZGh+vDxwp8HxnpH3yRHJDlyZszgZOk9DLbhmjbbGuCG8XT4Ei/6l9ykbc8h+9p+m4AL2tUrpwNPDR0yOOSSvAv4LeDsqnpmqL4og7+LQ5KTgBXAI+Ppcr+/503AeUleneREBn3edqj728PPAA9U1Y6Zwri2574+h5jL9+ehPuM/h1cOrGJwtcDDwIfG3U/r6S0Mdv/uAra2xyrgauDuVt8ELBlznycxuCrlq8C9M9sPOBbYDDwEfAE4ZgK26RHAk8BRQ7Wxb08GQbYL+DsGx4TX7mv7Mbha5Y/ae/VuYGrMfW5jcEx75j36sTbvP23vh63AHcB7xtznPn/PwIfa9nwQOHOcfbb6nwD/ao95x7I99/M5NGfvT285IknqZL4eqpIkjYnBIUnqxOCQJHVicEiSOjE4JEmdGBySpE4MDklSJ/8ffcaw38dJVswAAAAASUVORK5CYII=","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["# Seeing the  distribution of sentence length in order to figure out how many words we can replace during augmentation.\n","\n","final_df.query(\"Actual_Sentiment == 1\")[\"Review_len\"].plot(kind=\"hist\",xlim=(0,200))"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:03:31.045985Z","iopub.status.busy":"2021-08-18T11:03:31.045596Z","iopub.status.idle":"2021-08-18T11:03:39.811164Z","shell.execute_reply":"2021-08-18T11:03:39.809735Z","shell.execute_reply.started":"2021-08-18T11:03:31.045945Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n","  '\"sox\" backend is being deprecated. '\n"]},{"name":"stdout","output_type":"stream","text":["\n","As with all jobs, your experience leave look greatly upon your manager. Atomic number 53 have great, bonnie and misfortunate managers during my time there. I enjoyed the work and my coworkers. Their benefits package and employee perks be peachy.\n","\n","\n","As with all jobs, your experience will bet greatly upon your director. I have great, fair and poor managers during my time there. I enjoy the study and my coworkers. Their benefits package and employee fringe benefit are great.\n","\n","\n","As with all jobs, your experience will reckon greatly upon your manager. I have great, fair and poor managers during my fourth dimension on that point. Ace enjoyed the work and my coworkers. Their benefits package and employee perks be great.\n","\n"]}],"source":["# Sample DEMO\n","\n","import nlpaug.augmenter.word as naw\n","aug = naw.SynonymAug(aug_src=\"wordnet\",aug_min=10) # Replace the words with their synonym.aug_min tells the no.of words to replace.\n","\n","for i in aug.augment(final_df[\"Review\"][1] , 3): # 3 represents the no,of augmented sentences we want to create.\n","    print(f\"\\n{i}\\n\")"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:03:39.812980Z","iopub.status.busy":"2021-08-18T11:03:39.812618Z","iopub.status.idle":"2021-08-18T11:03:39.819767Z","shell.execute_reply":"2021-08-18T11:03:39.818249Z","shell.execute_reply.started":"2021-08-18T11:03:39.812940Z"},"trusted":true},"outputs":[],"source":["def Augment_Review(df,augmenter=None,n_sentence=None,Sentiment=None):\n","    temp_df = df.query(f\"Actual_Sentiment == {Sentiment}\")\n","    temp_df.loc[:,\"Review\"] = temp_df.loc[:,\"Review\"].apply(lambda text : [result for result in augmenter.augment(text , n_sentence)])\n","    temp_df = temp_df.explode(\"Review\")\n","    df = pd.concat([df,temp_df] , axis=0)\n","    return df"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:03:39.821724Z","iopub.status.busy":"2021-08-18T11:03:39.821117Z","iopub.status.idle":"2021-08-18T11:03:39.857257Z","shell.execute_reply":"2021-08-18T11:03:39.856349Z","shell.execute_reply.started":"2021-08-18T11:03:39.821682Z"},"trusted":true},"outputs":[],"source":["# Splitting the data into train and test before we do augmentation(oversampling) so as to avoid data leakage. Their will be heigher chances that some of the augmented sentences\n","# of a review that is in training might end up in testing/validation set and our model might just learn those patterrn during training and perform too good while testing .\n","# To avoid this over estimate of testing accuracy we are performing augmentation(oversampling) seperatly for traina and validation set.\n","\n","df_train , df_test = train_test_split(final_df,test_size=0.2,random_state=101,stratify=final_df[\"Actual_Sentiment\"])\n","df_val , df_test = train_test_split(df_test,test_size=0.4,random_state=101,stratify=df_test[\"Actual_Sentiment\"])"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:03:39.858848Z","iopub.status.busy":"2021-08-18T11:03:39.858514Z","iopub.status.idle":"2021-08-18T11:03:39.864302Z","shell.execute_reply":"2021-08-18T11:03:39.863541Z","shell.execute_reply.started":"2021-08-18T11:03:39.858812Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(16646, 5)\n","(2497, 5)\n","(1665, 5)\n"]}],"source":["print(df_train.shape)\n","print(df_val.shape)\n","print(df_test.shape)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:03:39.866324Z","iopub.status.busy":"2021-08-18T11:03:39.865580Z","iopub.status.idle":"2021-08-18T11:03:59.829819Z","shell.execute_reply":"2021-08-18T11:03:59.828951Z","shell.execute_reply.started":"2021-08-18T11:03:39.866285Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  self._setitem_single_column(ilocs[0], value, pi)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>Review</th>\n","      <th>Actual_Sentiment</th>\n","      <th>Review_id</th>\n","      <th>Review_len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>21356</th>\n","      <td>21356</td>\n","      <td>The other people who just dont appreciate what...</td>\n","      <td>0</td>\n","      <td>10483</td>\n","      <td>53</td>\n","    </tr>\n","    <tr>\n","      <th>20083</th>\n","      <td>20083</td>\n","      <td>None come to mind at this time</td>\n","      <td>0</td>\n","      <td>9210</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>8404</th>\n","      <td>8404</td>\n","      <td>Local Management allowed to make decisions.</td>\n","      <td>2</td>\n","      <td>4239</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>3647</th>\n","      <td>3647</td>\n","      <td>Change in management with doctrine of hire you...</td>\n","      <td>1</td>\n","      <td>3648</td>\n","      <td>33</td>\n","    </tr>\n","    <tr>\n","      <th>6152</th>\n","      <td>6152</td>\n","      <td>I enjoyed the job though at times it could be ...</td>\n","      <td>2</td>\n","      <td>6153</td>\n","      <td>107</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>15133</th>\n","      <td>15133</td>\n","      <td>Management, schedules, Did I say Management?</td>\n","      <td>0</td>\n","      <td>2566</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>6522</th>\n","      <td>6522</td>\n","      <td>Good money</td>\n","      <td>2</td>\n","      <td>504</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>5962</th>\n","      <td>5962</td>\n","      <td>worked there 7 years, adept job, good money, a...</td>\n","      <td>1</td>\n","      <td>5963</td>\n","      <td>44</td>\n","    </tr>\n","    <tr>\n","      <th>16520</th>\n","      <td>16520</td>\n","      <td>short breaks</td>\n","      <td>0</td>\n","      <td>5118</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>9061</th>\n","      <td>9061</td>\n","      <td>good management</td>\n","      <td>2</td>\n","      <td>5408</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>22436 rows × 5 columns</p>\n","</div>"],"text/plain":["       index                                             Review  \\\n","21356  21356  The other people who just dont appreciate what...   \n","20083  20083                    None come to mind at this time    \n","8404    8404        Local Management allowed to make decisions.   \n","3647    3647  Change in management with doctrine of hire you...   \n","6152    6152  I enjoyed the job though at times it could be ...   \n","...      ...                                                ...   \n","15133  15133       Management, schedules, Did I say Management?   \n","6522    6522                                         Good money   \n","5962    5962  worked there 7 years, adept job, good money, a...   \n","16520  16520                                       short breaks   \n","9061    9061                                    good management   \n","\n","       Actual_Sentiment  Review_id  Review_len  \n","21356                 0      10483          53  \n","20083                 0       9210           7  \n","8404                  2       4239           6  \n","3647                  1       3648          33  \n","6152                  2       6153         107  \n","...                 ...        ...         ...  \n","15133                 0       2566           6  \n","6522                  2        504           2  \n","5962                  1       5963          44  \n","16520                 0       5118           2  \n","9061                  2       5408           2  \n","\n","[22436 rows x 5 columns]"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["train_augmented_df = Augment_Review(df_train,augmenter=aug,n_sentence=5,Sentiment=1)\n","df_train = shuffle(train_augmented_df)\n","df_train"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:03:59.832784Z","iopub.status.busy":"2021-08-18T11:03:59.832528Z","iopub.status.idle":"2021-08-18T11:04:02.465761Z","shell.execute_reply":"2021-08-18T11:04:02.464788Z","shell.execute_reply.started":"2021-08-18T11:03:59.832758Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  self._setitem_single_column(ilocs[0], value, pi)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>Review</th>\n","      <th>Actual_Sentiment</th>\n","      <th>Review_id</th>\n","      <th>Review_len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>21233</th>\n","      <td>21233</td>\n","      <td>Don’t practice the MBM philosophy on a site le...</td>\n","      <td>0</td>\n","      <td>10360</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>5506</th>\n","      <td>5506</td>\n","      <td>The company makes it known the you are replace...</td>\n","      <td>0</td>\n","      <td>5507</td>\n","      <td>42</td>\n","    </tr>\n","    <tr>\n","      <th>56</th>\n","      <td>56</td>\n","      <td>Do not work for this company ..they say produc...</td>\n","      <td>0</td>\n","      <td>57</td>\n","      <td>65</td>\n","    </tr>\n","    <tr>\n","      <th>20077</th>\n","      <td>20077</td>\n","      <td>Theyll keep getting better no place is perfect.</td>\n","      <td>0</td>\n","      <td>9204</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>1871</th>\n","      <td>1871</td>\n","      <td>Near self direction and culture but was strong...</td>\n","      <td>1</td>\n","      <td>1872</td>\n","      <td>31</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5659</th>\n","      <td>5659</td>\n","      <td>Like to learn and teach processes and procedur...</td>\n","      <td>2</td>\n","      <td>5660</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>899</th>\n","      <td>899</td>\n","      <td>love working for Molex .The benefits, the mana...</td>\n","      <td>2</td>\n","      <td>900</td>\n","      <td>79</td>\n","    </tr>\n","    <tr>\n","      <th>10137</th>\n","      <td>10137</td>\n","      <td>Get to be your own boss manage your own plants...</td>\n","      <td>2</td>\n","      <td>6885</td>\n","      <td>27</td>\n","    </tr>\n","    <tr>\n","      <th>3710</th>\n","      <td>3710</td>\n","      <td>my typical day is giving breaks, operating mac...</td>\n","      <td>2</td>\n","      <td>3711</td>\n","      <td>27</td>\n","    </tr>\n","    <tr>\n","      <th>8030</th>\n","      <td>8030</td>\n","      <td>Professioanl Training.</td>\n","      <td>2</td>\n","      <td>3610</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3362 rows × 5 columns</p>\n","</div>"],"text/plain":["       index                                             Review  \\\n","21233  21233  Don’t practice the MBM philosophy on a site le...   \n","5506    5506  The company makes it known the you are replace...   \n","56        56  Do not work for this company ..they say produc...   \n","20077  20077   Theyll keep getting better no place is perfect.    \n","1871    1871  Near self direction and culture but was strong...   \n","...      ...                                                ...   \n","5659    5659  Like to learn and teach processes and procedur...   \n","899      899  love working for Molex .The benefits, the mana...   \n","10137  10137  Get to be your own boss manage your own plants...   \n","3710    3710  my typical day is giving breaks, operating mac...   \n","8030    8030                             Professioanl Training.   \n","\n","       Actual_Sentiment  Review_id  Review_len  \n","21233                 0      10360           9  \n","5506                  0       5507          42  \n","56                    0         57          65  \n","20077                 0       9204           8  \n","1871                  1       1872          31  \n","...                 ...        ...         ...  \n","5659                  2       5660          20  \n","899                   2        900          79  \n","10137                 2       6885          27  \n","3710                  2       3711          27  \n","8030                  2       3610           2  \n","\n","[3362 rows x 5 columns]"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["val_augmented_df = Augment_Review(df_val,augmenter=aug,n_sentence=5,Sentiment=1)\n","df_val = shuffle(val_augmented_df)\n","df_val"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:04:02.467493Z","iopub.status.busy":"2021-08-18T11:04:02.467110Z","iopub.status.idle":"2021-08-18T11:04:02.481414Z","shell.execute_reply":"2021-08-18T11:04:02.480053Z","shell.execute_reply.started":"2021-08-18T11:04:02.467440Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["2    0.379613\n","0    0.310706\n","1    0.309681\n","Name: Actual_Sentiment, dtype: float64\n","2    0.380131\n","0    0.311124\n","1    0.308745\n","Name: Actual_Sentiment, dtype: float64\n","2    0.511712\n","0    0.418619\n","1    0.069670\n","Name: Actual_Sentiment, dtype: float64\n"]}],"source":["print(df_train[\"Actual_Sentiment\"].value_counts(normalize=True))\n","print(df_val[\"Actual_Sentiment\"].value_counts(normalize=True))\n","print(df_test[\"Actual_Sentiment\"].value_counts(normalize=True))\n","\n","# Distribution of data is almost same in train and val set now(Not required for test set). Now our class looks a little balanced."]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:04:02.484224Z","iopub.status.busy":"2021-08-18T11:04:02.483753Z","iopub.status.idle":"2021-08-18T11:04:06.035426Z","shell.execute_reply":"2021-08-18T11:04:06.034420Z","shell.execute_reply.started":"2021-08-18T11:04:02.484174Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d5171223d28c499b8b52b9197cb1b653","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3f3d36aaac0e4bb886902415d34de185","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7c87bf1743784431a3e8a5928aa8a20c","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/436k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["PRE_TRAINED_MODEL_NAME = \"bert-base-cased\"\n","tokenizer = transformers.BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME) # BERT expect the tokens in a specific format,so we are using bert base model for it."]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:04:06.037156Z","iopub.status.busy":"2021-08-18T11:04:06.036761Z","iopub.status.idle":"2021-08-18T11:04:06.049834Z","shell.execute_reply":"2021-08-18T11:04:06.048674Z","shell.execute_reply.started":"2021-08-18T11:04:06.037122Z"},"trusted":true},"outputs":[{"data":{"text/plain":["28996"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["len(tokenizer.get_vocab()) # So this BERT model has a vocab size of 29k. and it cannnot be changed/appended.If BERT find a word that is not in the vocab,\n","#  it splits that words in the letters of different length and see if those splitted small words are present or not in the vocab .\n","# So every broken word(of the main word in our text) except the first one looks like \"##letter\". If even after splitting the words, BERT doesnt find any \n","# matching token , it will assign it [UNK] token ."]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:04:06.052056Z","iopub.status.busy":"2021-08-18T11:04:06.051444Z","iopub.status.idle":"2021-08-18T11:04:06.058396Z","shell.execute_reply":"2021-08-18T11:04:06.057489Z","shell.execute_reply.started":"2021-08-18T11:04:06.052018Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[SEP]\n","102\n"]}],"source":["print(tokenizer.sep_token)\n","print(tokenizer.sep_token_id)"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:04:06.060544Z","iopub.status.busy":"2021-08-18T11:04:06.060084Z","iopub.status.idle":"2021-08-18T11:04:06.069821Z","shell.execute_reply":"2021-08-18T11:04:06.068815Z","shell.execute_reply.started":"2021-08-18T11:04:06.060458Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['As', 'with', 'all', 'jobs', ',', 'your', 'experience', 'will', 'depend', 'greatly', 'upon', 'your', 'manager', '.', 'I', 'had', 'great', ',', 'fair', 'and', 'poor', 'managers', 'during', 'my', 'time', 'there', '.', 'I', 'enjoyed', 'the', 'work', 'and', 'my', 'cow', '##or', '##kers', '.', 'Their', 'benefits', 'package', 'and', 'employee', 'per', '##ks', 'are', 'great', '.']\n","[1249, 1114, 1155, 5448, 117, 1240, 2541, 1209, 12864, 5958, 1852, 1240, 2618, 119, 146, 1125, 1632, 117, 4652, 1105, 2869, 11493, 1219, 1139, 1159, 1175, 119, 146, 4927, 1103, 1250, 1105, 1139, 13991, 1766, 8811, 119, 2397, 6245, 7305, 1105, 7775, 1679, 4616, 1132, 1632, 119]\n"]}],"source":["tokens = tokenizer.tokenize(final_df[\"Review\"][1])\n","print(tokens)\n","print(tokenizer.convert_tokens_to_ids(tokens))"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:04:06.075967Z","iopub.status.busy":"2021-08-18T11:04:06.075580Z","iopub.status.idle":"2021-08-18T11:04:06.084301Z","shell.execute_reply":"2021-08-18T11:04:06.083026Z","shell.execute_reply.started":"2021-08-18T11:04:06.075938Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['Lea', '##rned', 'tax', 'compliance', 'as', 'well', 'as', 'other', 'tax', 'concepts', '.', 'Strong', 'workplace', 'culture', 'centered', 'around', 'principles', 'of', 'MB', '##M', 'Management', '.', ',', 'Pleasant', 'ca', '##mara', '##der', '##ie', 'amongst', 'cow', '##or', '##kers', '.']\n","[12958, 23537, 3641, 14037, 1112, 1218, 1112, 1168, 3641, 8550, 119, 11661, 19328, 2754, 8663, 1213, 6551, 1104, 19443, 2107, 3973, 119, 117, 16836, 11019, 20377, 2692, 1663, 5690, 13991, 1766, 8811, 119]\n"]}],"source":["tokens = tokenizer.tokenize(final_df[\"Review\"][274])\n","print(tokens)\n","print(tokenizer.convert_tokens_to_ids(tokens))"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:04:06.089218Z","iopub.status.busy":"2021-08-18T11:04:06.088920Z","iopub.status.idle":"2021-08-18T11:04:06.095514Z","shell.execute_reply":"2021-08-18T11:04:06.094186Z","shell.execute_reply.started":"2021-08-18T11:04:06.089188Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['Ad', '##ity', '##a', 'is', 'eating', 'apple', '.']\n","[24930, 1785, 1161, 1110, 5497, 12075, 119]\n"]}],"source":["tokens = tokenizer.tokenize(\"Aditya is eating apple.\")\n","print(tokens)\n","print(tokenizer.convert_tokens_to_ids(tokens))"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:04:06.097611Z","iopub.status.busy":"2021-08-18T11:04:06.097196Z","iopub.status.idle":"2021-08-18T11:04:06.104275Z","shell.execute_reply":"2021-08-18T11:04:06.103216Z","shell.execute_reply.started":"2021-08-18T11:04:06.097573Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['Ad', '##ity', '##a', 'is', 'planning', 'to', 'buy', 'apple', 'laptop', '.']\n","[24930, 1785, 1161, 1110, 3693, 1106, 4417, 12075, 12574, 119]\n"]}],"source":["tokens = tokenizer.tokenize(\"Aditya is planning to buy apple laptop.\")\n","print(tokens)\n","print(tokenizer.convert_tokens_to_ids(tokens))\n","\n","# Notice that apple has the same token id."]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:04:06.106221Z","iopub.status.busy":"2021-08-18T11:04:06.105805Z","iopub.status.idle":"2021-08-18T11:04:06.121600Z","shell.execute_reply":"2021-08-18T11:04:06.120609Z","shell.execute_reply.started":"2021-08-18T11:04:06.106186Z"},"trusted":true},"outputs":[{"data":{"text/plain":["True"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["\"##ity\" in tokenizer.get_vocab()"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:04:06.123313Z","iopub.status.busy":"2021-08-18T11:04:06.122961Z","iopub.status.idle":"2021-08-18T11:04:06.134101Z","shell.execute_reply":"2021-08-18T11:04:06.133143Z","shell.execute_reply.started":"2021-08-18T11:04:06.123279Z"},"trusted":true},"outputs":[{"data":{"text/plain":["dict_keys(['input_ids', 'attention_mask'])"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["# max_length has to be decided based on the len of sentences we have in our corpus and is critical because we dont want lot of padding (0) and \n","# also increasing max_length increases the training time.\n","\n","encoding = tokenizer.encode_plus(final_df[\"Review\"][1],max_length=100,add_special_tokens=True,padding='max_length',\n","                                 truncation=True,return_attention_mask=True,return_token_type_ids=False,return_tensors=\"pt\")\n","\n","encoding.keys()"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:04:06.135966Z","iopub.status.busy":"2021-08-18T11:04:06.135579Z","iopub.status.idle":"2021-08-18T11:04:06.160456Z","shell.execute_reply":"2021-08-18T11:04:06.159425Z","shell.execute_reply.started":"2021-08-18T11:04:06.135932Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor([[  101,  1249,  1114,  1155,  5448,   117,  1240,  2541,  1209, 12864,\n","          5958,  1852,  1240,  2618,   119,   146,  1125,  1632,   117,  4652,\n","          1105,  2869, 11493,  1219,  1139,  1159,  1175,   119,   146,  4927,\n","          1103,  1250,  1105,  1139, 13991,  1766,  8811,   119,  2397,  6245,\n","          7305,  1105,  7775,  1679,  4616,  1132,  1632,   119,   102,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]])"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["encoding[\"input_ids\"] # 0 means padded to make the tensor of constant length of max_length.\n","# We can notice that the tensor starts with 101 which is token id for [CLS] token telling BERT that this is a classification problem.\n","# We also have 102 in the end , which is token id for [SEP]."]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:04:06.162059Z","iopub.status.busy":"2021-08-18T11:04:06.161704Z","iopub.status.idle":"2021-08-18T11:04:06.169545Z","shell.execute_reply":"2021-08-18T11:04:06.168395Z","shell.execute_reply.started":"2021-08-18T11:04:06.162024Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0]])"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["encoding[\"attention_mask\"] # It is 1 where actual tokens are there and 0 where padding is present."]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:04:06.171828Z","iopub.status.busy":"2021-08-18T11:04:06.171126Z","iopub.status.idle":"2021-08-18T11:04:06.179442Z","shell.execute_reply":"2021-08-18T11:04:06.178090Z","shell.execute_reply.started":"2021-08-18T11:04:06.171790Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['[CLS]', 'As', 'with', 'all', 'jobs', ',', 'your', 'experience', 'will', 'depend', 'greatly', 'upon', 'your', 'manager', '.', 'I', 'had', 'great', ',', 'fair', 'and', 'poor', 'managers', 'during', 'my', 'time', 'there', '.', 'I', 'enjoyed', 'the', 'work', 'and', 'my', 'cow', '##or', '##kers', '.', 'Their', 'benefits', 'package', 'and', 'employee', 'per', '##ks', 'are', 'great', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"]}],"source":["print(tokenizer.convert_ids_to_tokens(encoding[\"input_ids\"][0]))"]},{"cell_type":"markdown","metadata":{},"source":["## Creating DataLoader using pytorch for BERT model"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:04:06.182630Z","iopub.status.busy":"2021-08-18T11:04:06.181630Z","iopub.status.idle":"2021-08-18T11:04:06.192067Z","shell.execute_reply":"2021-08-18T11:04:06.191073Z","shell.execute_reply.started":"2021-08-18T11:04:06.182581Z"},"trusted":true},"outputs":[],"source":["class ReviewDataset(data.Dataset):\n","    \n","    def __init__(self,reviews_text,targets,tokenizer,max_len):\n","        self.reviews_text = reviews_text # It is a numpy array of reviews text(what we get by using df[\"Review\"].values).\n","#         So remember this an array of reviews and not a single review.\n","        self.targets = targets # Numpy array of targets i.e 1,2 and 3 in our case\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","        \n","    def __len__(self):\n","        return self.reviews_text.shape[0]\n","    \n","    def __getitem__(self,idx):\n","        \n","        encoding = self.tokenizer.encode_plus(self.reviews_text[idx],max_length=self.max_len,add_special_tokens=True,truncation=True,\n","                                         padding='max_length',return_attention_mask=True,return_token_type_ids=False,return_tensors=\"pt\")\n","        return {\n","            \"review_text\" : self.reviews_text[idx],\n","            \"x\" : encoding[\"input_ids\"].flatten(),\n","            \"y\": torch.tensor(self.targets[idx],dtype=torch.long),\n","            \"attention_mask\": encoding['attention_mask'].flatten()\n","        }\n","    \n","# Note : All of these 3 above defined methods are compulsory for Dataset class to work."]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:04:06.194528Z","iopub.status.busy":"2021-08-18T11:04:06.194167Z","iopub.status.idle":"2021-08-18T11:04:06.215682Z","shell.execute_reply":"2021-08-18T11:04:06.214757Z","shell.execute_reply.started":"2021-08-18T11:04:06.194497Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'review_text': 'The other people who just dont appreciate what they have and still carry the old DuPont way of thinking or think they know it all. Too much complaining and not willing to make a change. Insults others and gets away with it like bullies. Many leaders who cant stop micro-managing everyone and everything. ',\n"," 'x': tensor([  101,  1109,  1168,  1234,  1150,  1198,  1274,  1204,  8856,  1184,\n","          1152,  1138,  1105,  1253,  3564,  1103,  1385, 12786,  2101,  9921,\n","          1236,  1104,  2422,  1137,  1341,  1152,  1221,  1122,  1155,   119,\n","          6466,  1277, 19533,  1105,  1136,  4988,  1106,  1294,   170,  1849,\n","           119,  1130, 24661,  2145,  1639,  1105,  3370,  1283,  1114,  1122,\n","          1176, 12200,  1905,   119,  2408,  3478,  1150,  1169,  1204,  1831,\n","         17599,   118,  7204,  2490,  1105,  1917,   119,   102,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]),\n"," 'y': tensor(0),\n"," 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0])}"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["dataset = ReviewDataset(reviews_text = df_train[\"Review\"].to_numpy(),targets=df_train[\"Actual_Sentiment\"].to_numpy(),\n","                       tokenizer=tokenizer,max_len=100)\n","\n","next(iter(dataset))"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:04:06.219041Z","iopub.status.busy":"2021-08-18T11:04:06.218743Z","iopub.status.idle":"2021-08-18T11:04:06.225441Z","shell.execute_reply":"2021-08-18T11:04:06.224404Z","shell.execute_reply.started":"2021-08-18T11:04:06.219013Z"},"trusted":true},"outputs":[],"source":["def create_DataLoader(df,tokenizer,max_len,batch_size):\n","    \n","#     class_weights = 1/df[\"Actual_Sentiment\"].value_counts(normalize=True).sort_index().values\n","#     sample_weights = [0] * len(df)  \n","    \n","    dataset = ReviewDataset(reviews_text = df[\"Review\"].to_numpy(),\n","                            targets = df[\"Actual_Sentiment\"].to_numpy(),\n","                            tokenizer = tokenizer,\n","                            max_len = max_len)\n","    \n","#     for idx , review in enumerate(dataset):\n","#         sample_weights[idx] = class_weights[review['y'].item()]\n","        \n","#     my_sampler = WeightedRandomSampler(sample_weights,num_samples=len(dataset),replacement=True) \n","\n","    # Using a weighted random sampler so that to have almost same ratio of sample from each class in the dataset.\n","    # Setting up replacement=True will allow to duplicate data to match the ratio which is usefull in case of imbalanced dataset.\n","#     But as have already handled the imbalance by upsampling(augmenting) , we dont need to use it in here.\n","# This is specially useful when you dont want to upsample the data and you want NN to see data from each class in each batch\n","    \n","    return data.DataLoader(dataset,batch_size=batch_size,num_workers=4,shuffle=True) \n","    "]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:04:06.227458Z","iopub.status.busy":"2021-08-18T11:04:06.226831Z","iopub.status.idle":"2021-08-18T11:04:06.234760Z","shell.execute_reply":"2021-08-18T11:04:06.233962Z","shell.execute_reply.started":"2021-08-18T11:04:06.227412Z"},"trusted":true},"outputs":[],"source":["MAX_LEN = 100\n","BATCH_SIZE = 16 # No.of data input per step\n","EPOCHS = 2 # No.of times we want to train on all data.(step = total_data/batch_size)"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:04:06.237845Z","iopub.status.busy":"2021-08-18T11:04:06.237554Z","iopub.status.idle":"2021-08-18T11:04:06.243839Z","shell.execute_reply":"2021-08-18T11:04:06.242996Z","shell.execute_reply.started":"2021-08-18T11:04:06.237820Z"},"trusted":true},"outputs":[],"source":["train_DataLoader = create_DataLoader(df_train,tokenizer ,MAX_LEN, BATCH_SIZE)\n","test_DataLoader = create_DataLoader(df_test,tokenizer, MAX_LEN, BATCH_SIZE)\n","val_DataLoader = create_DataLoader(df_val,tokenizer, MAX_LEN, BATCH_SIZE)"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:04:06.246297Z","iopub.status.busy":"2021-08-18T11:04:06.246018Z","iopub.status.idle":"2021-08-18T11:04:06.253411Z","shell.execute_reply":"2021-08-18T11:04:06.252534Z","shell.execute_reply.started":"2021-08-18T11:04:06.246273Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<torch.utils.data.dataloader.DataLoader at 0x7fb164004990>"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["train_DataLoader"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:04:06.255731Z","iopub.status.busy":"2021-08-18T11:04:06.254919Z","iopub.status.idle":"2021-08-18T11:04:06.498408Z","shell.execute_reply":"2021-08-18T11:04:06.497486Z","shell.execute_reply.started":"2021-08-18T11:04:06.255694Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{'review_text': ['While 6-7 day work weeks is required here they do try to compensate by offering a luxurious benefits package: good insurance, 401k match of 7%, and 3 weeks paid vacation your first year  Very good offering for people without kids. Maintenance team is all top notch guys on 1st and lower skill guys thrown into off shifts with no clear job expectations given. Manager works very hard to give team members their vacation days and never rejects a vacation request. However, there is a particular problem with the dynamic of teamwork. While the lead tech is justly favored for his higher skill set, the missing element is that the rest of the team is never asked their thoughts on solutions. Additionally, work done by off-shifts is given far less credit due to team divisive politics endorsed by the lead tech himself. Often to the point of passing false and misleading information on to the manager who does not try to explore other angles to the information given about a techs work. ', 'All depends on where on plant you work. It wasnt bad but they pick and chose who they want to keep. A lot of knowledge walks out the door because they ask you to wear many hats with no pay raise or bonus.', 'less opportunities for contract staff ', 'Stay close with Technological Innovations ', 'Flexible working time. Friendly atmosphere. ', 'If you want to work on your days off you will enjoy this place. Compensation is good but I barely get to see my family due to the hours. They preach family first but when things are bad as far as production youll be working to meet demands.', 'Ive been at GP for about 3 years. I enjoy working here, and plan on staying. One of the best parts of working at Georgia-Pacific is their individualized approach to everything - compensation, development, expectations. I took this job, knowing that I could grow my career in different directions as I am not pegged in to the position title I currently have. My managers (had a few as Ive changed roles/departments) have all listened to where I want to go and helped me get there. MBM is something that I believe in and flows in to other aspects of my life, not just work. Its a company that believes in doing the right thing. ', 'Great pay and benefits. There’s a lot of opportunity to switch roles if desired and there is a lot of freedom to learn new tools. ', 'Old fashioned culture Unethical human resources ', 'Benefits. Insurance', 'it was an ok job very tolerable but management made it harder than it had to be. ', 'Pros -, Molex offers competitive salary, good benefits, and job security. , , Cons-, Difficult to Advance, especially from Inside Sales, Work and family balance', 'If you want to come in and do the same thing every day then this may be the job for you. there is no room for growth and management works of the good ol boy system. its all about who knows who. even with a college degree i couldnt move up in a company that has management with no college degree.', 'I do not have any cons ', 'i saw many people change ', 'Dynamic director in one of the macrocosm ` s largest integrated producer of polymers and fibers, in the first place for nylon, spandex, and polyester application. With a business mien in more than than 20 countries.'], 'x': tensor([[  101,  1799,   127,  ...,  2463,  1114,   102],\n","        [  101,  1398,  9113,  ...,     0,     0,     0],\n","        [  101,  1750,  6305,  ...,     0,     0,     0],\n","        ...,\n","        [  101,   146,  1202,  ...,     0,     0,     0],\n","        [  101,   178,  1486,  ...,     0,     0,     0],\n","        [  101,   141, 27500,  ...,     0,     0,     0]]), 'y': tensor([1, 1, 0, 2, 2, 1, 2, 2, 0, 0, 0, 1, 1, 0, 0, 1]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]])}\n"]}],"source":["for i in train_DataLoader:\n","    print(i)\n","    break\n","    \n","# If we see the below result,we have x,y and attention_mask as output in batch size=BATCH_SIZE and is in tensor format which is required by pytorch."]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:04:06.500903Z","iopub.status.busy":"2021-08-18T11:04:06.500339Z","iopub.status.idle":"2021-08-18T11:04:29.710485Z","shell.execute_reply":"2021-08-18T11:04:29.709527Z","shell.execute_reply.started":"2021-08-18T11:04:06.500860Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{0: 6971, 1: 6948, 2: 8517}\n"]}],"source":["from collections import Counter\n","\n","dict_ = {0:0,1:0,2:0}\n","\n","for i in train_DataLoader:\n","    y = i['y'].numpy()\n","    ans = Counter(y)\n","    dict_[0]+=ans[0]\n","    dict_[1]+=ans[1]\n","    dict_[2]+=ans[2]\n","            \n","print(dict_)\n","    "]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:04:29.712626Z","iopub.status.busy":"2021-08-18T11:04:29.712232Z","iopub.status.idle":"2021-08-18T11:04:29.882321Z","shell.execute_reply":"2021-08-18T11:04:29.881140Z","shell.execute_reply.started":"2021-08-18T11:04:29.712582Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([16, 100])\n","torch.Size([16])\n","torch.Size([16, 100])\n"]}],"source":["for data_value in train_DataLoader:\n","    print(data_value['x'].shape)\n","    print(data_value[\"y\"].shape)\n","    print(data_value[\"attention_mask\"].shape)\n","    break"]},{"cell_type":"markdown","metadata":{},"source":["## Building BERT Model"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:04:29.884233Z","iopub.status.busy":"2021-08-18T11:04:29.883946Z","iopub.status.idle":"2021-08-18T11:04:54.198438Z","shell.execute_reply":"2021-08-18T11:04:54.197401Z","shell.execute_reply.started":"2021-08-18T11:04:29.884202Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5d2ea30269ec4cb9b7e44c958aed8755","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9322f9f3b4fc4b84bc0abc954007c654","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/436M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["bert_model = transformers.BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:04:54.202824Z","iopub.status.busy":"2021-08-18T11:04:54.202452Z","iopub.status.idle":"2021-08-18T11:04:54.225937Z","shell.execute_reply":"2021-08-18T11:04:54.221860Z","shell.execute_reply.started":"2021-08-18T11:04:54.202785Z"},"trusted":true},"outputs":[{"data":{"text/plain":["BertModel(\n","  (embeddings): BertEmbeddings(\n","    (word_embeddings): Embedding(28996, 768, padding_idx=0)\n","    (position_embeddings): Embedding(512, 768)\n","    (token_type_embeddings): Embedding(2, 768)\n","    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (encoder): BertEncoder(\n","    (layer): ModuleList(\n","      (0): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (1): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (2): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (3): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (4): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (5): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (6): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (7): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (8): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (9): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (10): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (11): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (pooler): BertPooler(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (activation): Tanh()\n","  )\n",")"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["bert_model"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:04:54.227747Z","iopub.status.busy":"2021-08-18T11:04:54.227343Z","iopub.status.idle":"2021-08-18T11:04:54.238555Z","shell.execute_reply":"2021-08-18T11:04:54.237432Z","shell.execute_reply.started":"2021-08-18T11:04:54.227710Z"},"trusted":true},"outputs":[{"data":{"text/plain":["BertConfig {\n","  \"_name_or_path\": \"bert-base-cased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.6.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["bert_model.config"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:04:54.240385Z","iopub.status.busy":"2021-08-18T11:04:54.239801Z","iopub.status.idle":"2021-08-18T11:04:54.955562Z","shell.execute_reply":"2021-08-18T11:04:54.954543Z","shell.execute_reply.started":"2021-08-18T11:04:54.240345Z"},"trusted":true},"outputs":[],"source":["output = bert_model(input_ids = encoding[\"input_ids\"] , attention_mask = encoding[\"attention_mask\"])"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:04:54.957045Z","iopub.status.busy":"2021-08-18T11:04:54.956719Z","iopub.status.idle":"2021-08-18T11:04:54.967975Z","shell.execute_reply":"2021-08-18T11:04:54.967147Z","shell.execute_reply.started":"2021-08-18T11:04:54.957012Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([1, 100, 768])\n","torch.Size([1, 768])\n"]}],"source":["print(output[\"last_hidden_state\"].shape)\n","print(output[\"pooler_output\"].shape)\n","\n","#  You can think of the pooler_output as a summary of the content, according to BERT\n","#  768 is the number of hidden units in the feedforward-networks."]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:04:54.976283Z","iopub.status.busy":"2021-08-18T11:04:54.970287Z","iopub.status.idle":"2021-08-18T11:04:55.092638Z","shell.execute_reply":"2021-08-18T11:04:55.091710Z","shell.execute_reply.started":"2021-08-18T11:04:54.976229Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor([ 5.6250e-01, -3.7724e-02,  4.8827e-01, -4.6143e-01,  3.5253e-01,\n","         1.3799e-01,  5.2483e-01, -2.7420e-01,  2.5858e-01, -3.1834e-01,\n","         4.1570e-02, -9.9064e-02, -8.2742e-02,  1.3999e-03,  1.2403e-01,\n","        -1.4388e-01, -2.4384e-01,  1.5486e-01, -1.9335e-01, -2.0739e-01,\n","        -7.5669e-01, -7.8712e-01, -6.8274e-02, -1.8052e-01,  4.5436e-01,\n","         1.5646e-01,  1.1853e-01,  9.8480e-01,  4.8943e-01,  3.5852e-01,\n","        -3.6760e-01,  6.1108e-02, -1.1151e+00, -8.8111e-02, -3.5701e-01,\n","         1.0242e-02, -3.9045e-01,  6.9933e-01, -2.6277e-01, -6.4659e-01,\n","         2.8598e-01,  1.0038e-01,  4.0935e-01,  8.5437e-02, -7.5991e-01,\n","        -9.5682e-01,  4.4303e-01,  3.1457e-01, -6.6107e-01,  2.7646e-01,\n","        -1.5802e-01,  2.6734e-01,  3.8362e-02, -8.1756e-02,  1.0833e-01,\n","         9.5640e-01,  5.6366e-02,  9.6733e-02,  3.1549e-02,  9.9561e-01,\n","        -4.7049e-01,  1.2572e-01,  3.8552e-01,  4.8482e-01,  3.9733e-01,\n","         3.7676e-01, -5.5212e-01, -9.4722e-02,  2.4739e-01, -7.7361e-01,\n","         5.3125e-01, -3.2568e-01, -2.9996e-02,  1.0059e-01, -1.6632e-01,\n","         4.1704e-02,  2.6261e-01, -1.4213e-01,  3.0379e-01, -5.2980e-01,\n","         6.1869e-01,  2.8059e-01, -2.6777e-01,  5.3590e-01,  1.2911e-01,\n","         3.2831e-01, -1.1890e-01, -2.7982e-02,  5.6598e-01, -3.5490e-01,\n","         2.3757e-01, -3.9120e-01, -1.8303e-02, -7.4921e-01,  9.6078e-02,\n","         3.2783e-01,  1.1791e-01, -2.0963e-01, -4.3276e-01,  1.0757e-01,\n","        -1.0501e-01, -7.5418e-02, -7.4693e-02, -9.2628e-01,  7.8416e-01,\n","         1.9413e-03, -7.2844e-01, -6.7581e-01, -8.2046e-01,  3.0961e-01,\n","        -2.3257e-02,  3.4394e-01,  1.4648e-01,  3.8185e-01, -1.1085e-01,\n","         2.5069e-01, -5.2893e-01,  8.6677e-02, -2.5524e-03,  5.9303e-01,\n","        -2.0715e-01, -8.6203e-01,  1.9788e-01, -4.4724e-01, -8.2995e-02,\n","        -1.4941e-01, -9.4333e-02, -3.6900e-01, -1.5678e-01,  1.7062e-01,\n","        -3.7007e-01,  1.1957e-01,  3.4304e-01, -1.9817e-01,  2.4615e-01,\n","         3.4476e-01,  4.6783e-01,  5.0567e-01, -1.0770e+00, -7.3041e-01,\n","        -1.6621e-01,  2.1667e-01,  7.3159e-01, -4.1632e-01,  5.1411e-01,\n","         6.7872e-03, -2.3073e-02,  1.3712e-01,  2.8949e-01,  6.1962e-01,\n","        -7.6713e-01,  4.2862e-01,  2.4448e-01,  5.8414e-01,  8.7298e-02,\n","        -2.9084e-01,  3.0333e-01, -3.4738e-01,  2.6740e-01, -5.8532e-01,\n","         1.9268e-01, -1.6579e-01, -2.9373e-01, -8.8148e-01, -1.3526e-01,\n","        -4.4490e-01,  2.7062e-01, -1.4230e-01,  5.0953e-01, -4.7697e-01,\n","         4.0806e-01,  3.1793e-02,  3.6941e-01,  1.8656e-01,  3.1121e-01,\n","        -1.0610e-01,  5.0859e-01, -2.6844e-04,  8.7957e-01,  5.4310e-01,\n","        -3.8799e-01,  3.2874e-02, -3.7317e-01, -4.2766e-01,  1.1514e+00,\n","         4.3346e-02, -1.1577e-01,  4.2275e-01,  2.2821e-01,  7.4836e-02,\n","        -8.6032e-02,  4.9426e-01, -4.2652e-01, -3.3144e-01, -3.6563e-01,\n","         2.1388e-03,  3.7690e-01,  5.0020e-02,  1.0773e-02, -2.6670e-01,\n","        -7.3062e-01,  4.0534e-01, -2.8782e-01,  3.2934e-01, -2.0788e-01,\n","        -3.4997e-01, -5.8965e-01, -1.3401e-01, -1.3613e-01, -7.2860e-01,\n","         1.0596e-01,  7.8427e-01, -1.5045e-01,  4.4970e-01, -3.5458e-01,\n","        -6.2727e-01,  2.6265e-01, -4.4052e-01, -2.0904e-01,  7.5162e-01,\n","        -2.5498e-01, -2.6015e-01, -2.7256e-01, -5.1518e-01, -5.1771e-01,\n","         2.6597e-01, -2.7243e-01, -1.0603e-01,  4.8149e-01,  4.5967e-02,\n","         7.8791e-01,  7.9890e-01, -1.1441e-01, -1.7153e-01,  6.2816e-01,\n","        -8.1953e-01, -1.1590e-01, -1.4705e-01, -3.9972e-01,  7.9277e-01,\n","        -3.7992e-01, -4.4999e-01,  4.3574e-01,  1.2759e-02,  2.8132e-01,\n","         5.1347e-01, -7.7808e-01,  4.1911e-01, -8.7894e-02, -8.8633e-02,\n","         1.0226e+00,  2.9473e-01, -3.0564e-01,  3.6379e-01,  3.1621e-01,\n","        -2.7406e-01,  2.3837e-01,  5.2659e-01,  3.6550e-01, -1.1567e-01,\n","        -1.9100e-01,  3.7451e-03, -4.2281e-01, -8.8558e-01, -5.7101e-01,\n","        -5.0635e-01,  1.4371e-01, -5.6518e-01,  2.5283e-01,  7.6964e-01,\n","        -1.3813e-01,  4.5872e-01, -4.0456e-01,  8.5128e-01, -6.2542e-01,\n","         6.8690e-01,  2.5661e-01, -3.0682e-01, -3.8768e-01, -2.6986e-01,\n","         4.4601e-01, -4.0606e-01, -1.1095e-02,  4.1159e-01, -3.3088e-01,\n","         1.3005e-01,  1.3675e-02,  7.0601e-01,  1.5105e-01, -1.2156e-01,\n","        -7.1466e-01, -1.5134e-01,  3.4225e-01,  1.6085e-01, -2.0830e-02,\n","         9.8207e-01, -4.4713e-01,  1.5653e-01, -1.3110e+00,  2.3590e-01,\n","         4.8878e-01,  2.1289e-01,  5.4302e-01,  6.4833e-01,  2.1281e-02,\n","         2.6352e-02,  2.6339e-01, -1.7942e-01,  5.1518e-01,  2.2496e-01,\n","         7.1535e-01, -2.1269e-01, -6.7892e-01,  1.5208e-02,  1.0960e-01,\n","         4.8232e-01,  1.4979e-01, -3.7283e-01, -8.1137e-01,  1.6414e-02,\n","        -8.0124e-02, -4.6970e-01, -4.9402e-01,  5.7945e-01, -4.0125e-02,\n","         4.1317e-01,  1.4680e-02, -2.7389e-01, -2.7882e-01, -4.4297e-02,\n","        -4.2227e-01, -2.3526e-01,  3.2014e-01,  2.8384e-01, -1.8415e-02,\n","         9.4508e-02, -8.3787e-01,  1.0485e+00,  5.7730e-01,  1.6546e-01,\n","         1.0924e-01,  3.7977e-01, -1.0840e-01, -2.8918e-01,  3.5193e-01,\n","         1.0153e+00,  4.0683e-01, -8.1371e-02, -7.9879e-01,  2.0870e-01,\n","        -3.7342e-01, -7.6678e-01, -2.1777e-01,  1.1050e-01,  7.1919e-01,\n","         2.2844e-02,  4.0405e-01, -2.3927e-01,  7.9959e-02,  1.7823e-01,\n","        -2.0938e-01,  3.8688e-01, -1.6094e-01,  4.7001e-01,  1.4031e-01,\n","        -4.0291e-02,  6.6781e-01,  3.4669e-01, -2.1518e-01,  4.9288e-01,\n","         4.3768e-01,  9.2834e-01,  4.7067e-01,  3.5066e-01,  4.3090e-01,\n","        -1.9701e-01,  3.3523e-02, -4.8532e-01,  5.3616e-02, -1.5758e-01,\n","         8.2774e-01, -2.6088e-01, -1.3992e-01, -7.3357e-01, -2.1305e-01,\n","        -3.2113e-01, -3.3788e-01, -2.0318e-01, -2.1098e-01,  5.7955e-01,\n","         5.0968e-01,  1.0954e-01, -3.1772e-01, -5.3505e-02, -1.3962e-01,\n","        -1.0129e-01, -1.9259e-01,  1.3956e-01, -7.1182e-01,  3.0696e-01,\n","        -2.8513e-01, -5.1797e-01, -4.9014e-01,  1.4498e-01, -4.2972e-01,\n","        -3.6568e-01, -3.9636e-01, -2.4982e-01, -5.2496e-01,  4.4938e-01,\n","        -9.0327e-01, -4.2393e-01,  4.2308e-01,  5.8811e-01, -2.1149e-01,\n","        -1.6771e-01, -4.5699e-01,  8.2222e-02,  2.1524e-01,  6.1070e-01,\n","        -4.1845e-01, -2.7913e-03,  9.1390e-03,  3.5824e-01,  4.7085e-01,\n","         1.3361e+00,  2.1273e-01, -1.0912e-01, -3.8862e-01,  1.0663e+00,\n","         2.1299e-01, -1.5434e-02,  8.6671e-01,  2.7589e-01, -4.0484e-02,\n","         5.9718e-02,  2.4497e-01, -3.8518e-02,  2.9115e-01, -8.8248e-01,\n","         9.1990e-02, -3.5982e-01,  2.2025e-01, -1.4002e-01,  1.5318e-01,\n","        -1.9502e-01,  3.0068e-01, -4.9748e-02, -1.0189e-01,  1.3398e-01,\n","         3.5381e-01,  4.2724e-01, -2.7062e-02,  7.1289e-02,  3.8698e-01,\n","        -8.7405e-02, -5.0176e-01, -8.7429e-03,  1.9441e-01, -3.4936e-01,\n","        -4.0045e-01, -5.1259e-01,  4.0422e-01,  5.0737e-01,  7.2329e-02,\n","        -5.0914e-01,  6.6300e-01,  3.1967e-01, -7.4597e-01, -1.8255e-01,\n","         7.5251e-01,  7.3240e-01,  4.8390e-01, -9.9429e-02, -8.3775e-01,\n","        -1.6504e-01, -3.6517e-02, -6.2557e-02, -1.9715e-01,  3.4461e-01,\n","        -6.0245e-01,  5.4955e-02,  3.5278e-03, -6.4256e-01,  2.9305e-01,\n","         8.6379e-02,  2.2057e-01,  3.4046e-01,  1.1761e+00,  6.0190e-01,\n","        -1.1324e-01,  1.4411e-01,  1.6080e-01, -1.9547e-01, -1.4687e-01,\n","        -9.1635e-01, -3.4931e-01, -3.8473e-01, -8.3370e-01, -6.4360e-01,\n","         2.2455e-02, -7.9376e-01,  5.3094e-01, -5.6181e-02, -1.7931e-01,\n","         8.7337e-01,  1.1006e-01,  4.3945e-01,  2.8359e-01,  2.8318e-01,\n","         1.6010e-01, -4.5143e-01, -6.7334e-02,  5.2913e-01, -1.9293e-01,\n","         3.7540e-01,  9.7200e-02,  6.0607e-01, -4.3108e-02,  2.5791e-01,\n","         7.0782e-02, -2.5609e-01, -3.9003e-01, -1.8156e-01,  3.0009e-01,\n","         8.9199e-02,  1.8996e-01,  3.9329e-01, -1.6123e-01, -2.1869e-03,\n","        -5.7565e-01, -6.0958e-01, -2.8286e-02, -5.6924e-01,  9.2352e-01,\n","        -1.4933e-01,  6.0950e-01,  7.8269e-03,  7.5084e-03, -2.4161e-01,\n","        -5.9949e-01, -3.9598e-01, -6.3381e-01,  2.7365e-01,  3.4574e-01,\n","        -1.9358e-01, -3.7593e-01,  5.2031e-02, -2.7797e-01,  2.7798e-02,\n","         2.9794e-01,  7.2810e-01, -1.0602e+00, -8.7874e-02, -4.2807e-01,\n","        -2.4067e-01, -7.5936e-01, -8.2861e+00,  8.3726e-01,  4.9882e-01,\n","        -3.1185e-01,  4.1881e-01,  5.2122e-01, -1.2910e-01,  2.2017e-02,\n","        -4.8973e-02, -9.6531e-02,  3.8768e-01, -4.5968e-01, -3.2702e-01,\n","         3.0408e-01, -8.9349e-02, -3.3305e-01, -1.1498e+00,  1.8896e-01,\n","         2.8469e-01,  5.7622e-02,  2.6224e-01, -7.4901e-03, -4.0966e-01,\n","         3.3240e-01,  2.4808e-01,  7.0422e-02,  5.1517e-01,  1.4407e-01,\n","         7.1692e-01,  1.5010e-01, -1.1540e-01,  1.4507e-01, -4.6897e-01,\n","        -9.9014e-01,  2.0778e-01,  2.1545e-01,  2.1656e-01, -2.3576e-01,\n","        -5.0470e-01, -2.6883e-01, -4.4773e-01,  2.3560e-01,  2.4310e-01,\n","         5.5151e-01,  8.2400e-01,  3.7086e-01, -4.5401e-01, -3.3173e-01,\n","        -1.7923e-01,  1.1866e+00,  3.1079e-01,  5.1639e-01,  3.7722e-01,\n","        -5.6397e-01,  5.0744e-01,  1.5165e-01,  5.1390e-01,  3.7298e-01,\n","         9.5015e-02, -2.0442e-01, -5.7551e-01, -6.9320e-01,  4.2269e-01,\n","        -1.8980e-02,  1.0905e-01,  5.7899e-01, -1.8504e-01,  1.0409e-01,\n","         4.1646e-01,  4.3442e-02, -4.5964e-01, -1.7506e-01,  2.5078e-01,\n","        -1.9865e-01, -1.0698e-01,  1.8845e-01, -4.7101e-01, -7.9274e-01,\n","        -4.2869e-01,  3.2975e-01, -5.1323e-01,  5.8489e-01,  3.6257e-01,\n","         7.2601e-02,  7.7482e-02, -1.0954e+00, -4.0868e-01, -5.6857e-01,\n","         4.3212e-01, -1.0761e-01, -7.4950e-01,  2.2396e-01,  4.0537e-01,\n","         1.4274e-01, -2.0845e-01, -2.1433e-01, -1.8230e-01, -1.7837e-01,\n","         7.9722e-02,  3.6237e-02, -5.5354e-02,  2.1547e-01, -3.8164e-01,\n","         5.9160e-02,  3.2993e-01,  1.4974e-01, -9.3896e-03, -4.4157e-01,\n","        -5.7385e-01, -2.9105e-01, -4.7507e-01,  2.2599e-01, -4.3897e-01,\n","         8.1261e-01,  2.6411e-01,  1.3794e-02,  7.5983e-01, -3.6050e-01,\n","        -3.0743e-01, -9.2487e-02,  1.6144e-01,  3.1935e-01, -1.1786e-01,\n","        -2.1246e-01,  4.2822e-02,  2.2088e-01, -1.3271e-01, -4.0227e-02,\n","         2.7339e-01,  2.1181e-02, -9.8575e-02,  4.8331e-01, -4.3226e-01,\n","         7.1681e-01, -2.9021e-01, -2.3400e-02, -8.6707e-02,  6.6086e-02,\n","        -1.0119e+00,  4.7683e-02, -6.4510e-01,  3.1275e-01,  4.5968e-01,\n","        -2.6159e-01, -3.5621e-01, -6.4758e-01,  1.5860e-01, -2.8124e-01,\n","        -3.8703e-01, -2.3011e-03,  2.5800e-01,  3.7140e-01, -1.1011e-01,\n","        -4.5611e-01, -4.5682e-01, -2.1086e-01,  3.9175e-03,  4.5970e-01,\n","        -2.4739e-01, -2.0785e-01, -6.4373e-02, -1.6573e-01,  4.1767e-01,\n","        -2.0133e-02, -2.8724e-01, -3.3720e-03, -5.6528e-02, -9.3917e-01,\n","        -1.9267e-02,  5.8368e-01,  8.1882e-01, -7.9107e-01,  8.4900e-01,\n","         4.8911e-01, -2.2772e-01,  2.3918e-01, -1.2582e-02,  1.5217e-01,\n","         6.8980e-01, -1.1304e-01, -1.3273e-01,  1.6182e-01,  2.0999e-01,\n","        -7.7128e-03,  2.1386e-01,  1.6017e-01,  2.7865e-01,  8.2155e-02,\n","        -2.4072e-01,  1.6112e-01,  5.6074e-01, -2.0943e-01, -5.9117e-01,\n","         2.3338e-01,  1.2502e-01, -2.2897e-01, -1.0185e-01, -9.9627e-02,\n","         1.1438e-02, -1.5354e-02, -5.1992e-02, -5.6688e-01, -2.8635e-02,\n","        -3.6327e-02, -6.7094e-02,  1.2516e-01, -2.6610e-01,  4.7880e-01,\n","         8.2829e-02, -8.6836e-02,  6.3795e-01], grad_fn=<SelectBackward>)"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["output['last_hidden_state'][0][6]"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:04:55.099119Z","iopub.status.busy":"2021-08-18T11:04:55.097038Z","iopub.status.idle":"2021-08-18T11:04:55.115832Z","shell.execute_reply":"2021-08-18T11:04:55.114993Z","shell.execute_reply.started":"2021-08-18T11:04:55.099064Z"},"trusted":true},"outputs":[],"source":["class SentimentModel(nn.Module):\n","    \n","    def __init__(self,n_classes):\n","        super().__init__()\n","        \n","        self.bert_layer = transformers.BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME) # With this we have applied BERT embedding layer and 12 multi-head attention layers whose weights are already trained.\n","        \n","        self.dropout_layer = nn.Dropout(0.3) # Applying some regularization\n","        \n","        self.linear_layer = nn.Linear(self.bert_layer.config.hidden_size,n_classes)  # As output of BERT layer will be 1x768 ,so applying a Linear layer with input 768 and output as no.of classes,\n","#         to linearly transform this 1x768 vector into 1x3 (i.e our no.of classes)\n","                \n","        \n","    def forward(self,input_ids,attention_mask):\n","        \n","        output = self.bert_layer(input_ids=input_ids,attention_mask=attention_mask)\n","#         print(output['pooler_output'])\n","        output =  self.dropout_layer(output['pooler_output'])\n","#         print(output)\n","        output = self.linear_layer(output)\n","#         print(output)\n","        return output\n","\n","\n","# Note that we're returning the raw output of the last layer since that is required for the cross-entropy loss function in PyTorch to work.\n","# Later for predictions we need to use a softmax layer over this raw output to get the probabilities that adds upto 1.\n","        "]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:04:55.124991Z","iopub.status.busy":"2021-08-18T11:04:55.121133Z","iopub.status.idle":"2021-08-18T11:05:00.967661Z","shell.execute_reply":"2021-08-18T11:05:00.966602Z","shell.execute_reply.started":"2021-08-18T11:04:55.124952Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"data":{"text/plain":["tensor([[ 0.4491,  1.0892, -0.3330],\n","        [-0.6343,  0.9539, -0.0439],\n","        [ 0.3517,  0.7660,  0.5686],\n","        [ 0.1061,  0.6901,  0.3622],\n","        [-0.1088,  0.2563, -0.1440],\n","        [-0.3953,  0.4811,  0.5300],\n","        [-0.8367,  0.8156,  0.1421],\n","        [ 0.4939,  0.8707,  0.1939],\n","        [-0.2977,  0.8630,  0.1560],\n","        [-0.1216,  0.7898,  0.3842],\n","        [ 0.5814,  0.5885,  0.4441],\n","        [ 0.2673,  0.5839,  0.6704],\n","        [-0.0501,  0.5383,  0.3934],\n","        [-0.5653,  0.5232,  0.5541],\n","        [ 0.1287,  0.5934,  0.3314],\n","        [ 0.1427,  0.8540,  0.5256]], grad_fn=<AddmmBackward>)"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["model = SentimentModel(n_classes=3)\n","model(data_value[\"x\"],data_value[\"attention_mask\"])\n","\n","# Note that the values over axis=1 doesnt add upto 1."]},{"cell_type":"code","execution_count":49,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:05:00.969601Z","iopub.status.busy":"2021-08-18T11:05:00.969059Z","iopub.status.idle":"2021-08-18T11:05:01.010768Z","shell.execute_reply":"2021-08-18T11:05:01.009966Z","shell.execute_reply.started":"2021-08-18T11:05:00.969560Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["bert_layer.embeddings.word_embeddings.weight\n","bert_layer.embeddings.position_embeddings.weight\n","bert_layer.embeddings.token_type_embeddings.weight\n","bert_layer.embeddings.LayerNorm.weight\n","bert_layer.embeddings.LayerNorm.bias\n","bert_layer.encoder.layer.0.attention.self.query.weight\n","bert_layer.encoder.layer.0.attention.self.query.bias\n","bert_layer.encoder.layer.0.attention.self.key.weight\n","bert_layer.encoder.layer.0.attention.self.key.bias\n","bert_layer.encoder.layer.0.attention.self.value.weight\n","bert_layer.encoder.layer.0.attention.self.value.bias\n","bert_layer.encoder.layer.0.attention.output.dense.weight\n","bert_layer.encoder.layer.0.attention.output.dense.bias\n","bert_layer.encoder.layer.0.attention.output.LayerNorm.weight\n","bert_layer.encoder.layer.0.attention.output.LayerNorm.bias\n","bert_layer.encoder.layer.0.intermediate.dense.weight\n","bert_layer.encoder.layer.0.intermediate.dense.bias\n","bert_layer.encoder.layer.0.output.dense.weight\n","bert_layer.encoder.layer.0.output.dense.bias\n","bert_layer.encoder.layer.0.output.LayerNorm.weight\n","bert_layer.encoder.layer.0.output.LayerNorm.bias\n","bert_layer.encoder.layer.1.attention.self.query.weight\n","bert_layer.encoder.layer.1.attention.self.query.bias\n","bert_layer.encoder.layer.1.attention.self.key.weight\n","bert_layer.encoder.layer.1.attention.self.key.bias\n","bert_layer.encoder.layer.1.attention.self.value.weight\n","bert_layer.encoder.layer.1.attention.self.value.bias\n","bert_layer.encoder.layer.1.attention.output.dense.weight\n","bert_layer.encoder.layer.1.attention.output.dense.bias\n","bert_layer.encoder.layer.1.attention.output.LayerNorm.weight\n","bert_layer.encoder.layer.1.attention.output.LayerNorm.bias\n","bert_layer.encoder.layer.1.intermediate.dense.weight\n","bert_layer.encoder.layer.1.intermediate.dense.bias\n","bert_layer.encoder.layer.1.output.dense.weight\n","bert_layer.encoder.layer.1.output.dense.bias\n","bert_layer.encoder.layer.1.output.LayerNorm.weight\n","bert_layer.encoder.layer.1.output.LayerNorm.bias\n","bert_layer.encoder.layer.2.attention.self.query.weight\n","bert_layer.encoder.layer.2.attention.self.query.bias\n","bert_layer.encoder.layer.2.attention.self.key.weight\n","bert_layer.encoder.layer.2.attention.self.key.bias\n","bert_layer.encoder.layer.2.attention.self.value.weight\n","bert_layer.encoder.layer.2.attention.self.value.bias\n","bert_layer.encoder.layer.2.attention.output.dense.weight\n","bert_layer.encoder.layer.2.attention.output.dense.bias\n","bert_layer.encoder.layer.2.attention.output.LayerNorm.weight\n","bert_layer.encoder.layer.2.attention.output.LayerNorm.bias\n","bert_layer.encoder.layer.2.intermediate.dense.weight\n","bert_layer.encoder.layer.2.intermediate.dense.bias\n","bert_layer.encoder.layer.2.output.dense.weight\n","bert_layer.encoder.layer.2.output.dense.bias\n","bert_layer.encoder.layer.2.output.LayerNorm.weight\n","bert_layer.encoder.layer.2.output.LayerNorm.bias\n","bert_layer.encoder.layer.3.attention.self.query.weight\n","bert_layer.encoder.layer.3.attention.self.query.bias\n","bert_layer.encoder.layer.3.attention.self.key.weight\n","bert_layer.encoder.layer.3.attention.self.key.bias\n","bert_layer.encoder.layer.3.attention.self.value.weight\n","bert_layer.encoder.layer.3.attention.self.value.bias\n","bert_layer.encoder.layer.3.attention.output.dense.weight\n","bert_layer.encoder.layer.3.attention.output.dense.bias\n","bert_layer.encoder.layer.3.attention.output.LayerNorm.weight\n","bert_layer.encoder.layer.3.attention.output.LayerNorm.bias\n","bert_layer.encoder.layer.3.intermediate.dense.weight\n","bert_layer.encoder.layer.3.intermediate.dense.bias\n","bert_layer.encoder.layer.3.output.dense.weight\n","bert_layer.encoder.layer.3.output.dense.bias\n","bert_layer.encoder.layer.3.output.LayerNorm.weight\n","bert_layer.encoder.layer.3.output.LayerNorm.bias\n","bert_layer.encoder.layer.4.attention.self.query.weight\n","bert_layer.encoder.layer.4.attention.self.query.bias\n","bert_layer.encoder.layer.4.attention.self.key.weight\n","bert_layer.encoder.layer.4.attention.self.key.bias\n","bert_layer.encoder.layer.4.attention.self.value.weight\n","bert_layer.encoder.layer.4.attention.self.value.bias\n","bert_layer.encoder.layer.4.attention.output.dense.weight\n","bert_layer.encoder.layer.4.attention.output.dense.bias\n","bert_layer.encoder.layer.4.attention.output.LayerNorm.weight\n","bert_layer.encoder.layer.4.attention.output.LayerNorm.bias\n","bert_layer.encoder.layer.4.intermediate.dense.weight\n","bert_layer.encoder.layer.4.intermediate.dense.bias\n","bert_layer.encoder.layer.4.output.dense.weight\n","bert_layer.encoder.layer.4.output.dense.bias\n","bert_layer.encoder.layer.4.output.LayerNorm.weight\n","bert_layer.encoder.layer.4.output.LayerNorm.bias\n","bert_layer.encoder.layer.5.attention.self.query.weight\n","bert_layer.encoder.layer.5.attention.self.query.bias\n","bert_layer.encoder.layer.5.attention.self.key.weight\n","bert_layer.encoder.layer.5.attention.self.key.bias\n","bert_layer.encoder.layer.5.attention.self.value.weight\n","bert_layer.encoder.layer.5.attention.self.value.bias\n","bert_layer.encoder.layer.5.attention.output.dense.weight\n","bert_layer.encoder.layer.5.attention.output.dense.bias\n","bert_layer.encoder.layer.5.attention.output.LayerNorm.weight\n","bert_layer.encoder.layer.5.attention.output.LayerNorm.bias\n","bert_layer.encoder.layer.5.intermediate.dense.weight\n","bert_layer.encoder.layer.5.intermediate.dense.bias\n","bert_layer.encoder.layer.5.output.dense.weight\n","bert_layer.encoder.layer.5.output.dense.bias\n","bert_layer.encoder.layer.5.output.LayerNorm.weight\n","bert_layer.encoder.layer.5.output.LayerNorm.bias\n","bert_layer.encoder.layer.6.attention.self.query.weight\n","bert_layer.encoder.layer.6.attention.self.query.bias\n","bert_layer.encoder.layer.6.attention.self.key.weight\n","bert_layer.encoder.layer.6.attention.self.key.bias\n","bert_layer.encoder.layer.6.attention.self.value.weight\n","bert_layer.encoder.layer.6.attention.self.value.bias\n","bert_layer.encoder.layer.6.attention.output.dense.weight\n","bert_layer.encoder.layer.6.attention.output.dense.bias\n","bert_layer.encoder.layer.6.attention.output.LayerNorm.weight\n","bert_layer.encoder.layer.6.attention.output.LayerNorm.bias\n","bert_layer.encoder.layer.6.intermediate.dense.weight\n","bert_layer.encoder.layer.6.intermediate.dense.bias\n","bert_layer.encoder.layer.6.output.dense.weight\n","bert_layer.encoder.layer.6.output.dense.bias\n","bert_layer.encoder.layer.6.output.LayerNorm.weight\n","bert_layer.encoder.layer.6.output.LayerNorm.bias\n","bert_layer.encoder.layer.7.attention.self.query.weight\n","bert_layer.encoder.layer.7.attention.self.query.bias\n","bert_layer.encoder.layer.7.attention.self.key.weight\n","bert_layer.encoder.layer.7.attention.self.key.bias\n","bert_layer.encoder.layer.7.attention.self.value.weight\n","bert_layer.encoder.layer.7.attention.self.value.bias\n","bert_layer.encoder.layer.7.attention.output.dense.weight\n","bert_layer.encoder.layer.7.attention.output.dense.bias\n","bert_layer.encoder.layer.7.attention.output.LayerNorm.weight\n","bert_layer.encoder.layer.7.attention.output.LayerNorm.bias\n","bert_layer.encoder.layer.7.intermediate.dense.weight\n","bert_layer.encoder.layer.7.intermediate.dense.bias\n","bert_layer.encoder.layer.7.output.dense.weight\n","bert_layer.encoder.layer.7.output.dense.bias\n","bert_layer.encoder.layer.7.output.LayerNorm.weight\n","bert_layer.encoder.layer.7.output.LayerNorm.bias\n","bert_layer.encoder.layer.8.attention.self.query.weight\n","bert_layer.encoder.layer.8.attention.self.query.bias\n","bert_layer.encoder.layer.8.attention.self.key.weight\n","bert_layer.encoder.layer.8.attention.self.key.bias\n","bert_layer.encoder.layer.8.attention.self.value.weight\n","bert_layer.encoder.layer.8.attention.self.value.bias\n","bert_layer.encoder.layer.8.attention.output.dense.weight\n","bert_layer.encoder.layer.8.attention.output.dense.bias\n","bert_layer.encoder.layer.8.attention.output.LayerNorm.weight\n","bert_layer.encoder.layer.8.attention.output.LayerNorm.bias\n","bert_layer.encoder.layer.8.intermediate.dense.weight\n","bert_layer.encoder.layer.8.intermediate.dense.bias\n","bert_layer.encoder.layer.8.output.dense.weight\n","bert_layer.encoder.layer.8.output.dense.bias\n","bert_layer.encoder.layer.8.output.LayerNorm.weight\n","bert_layer.encoder.layer.8.output.LayerNorm.bias\n","bert_layer.encoder.layer.9.attention.self.query.weight\n","bert_layer.encoder.layer.9.attention.self.query.bias\n","bert_layer.encoder.layer.9.attention.self.key.weight\n","bert_layer.encoder.layer.9.attention.self.key.bias\n","bert_layer.encoder.layer.9.attention.self.value.weight\n","bert_layer.encoder.layer.9.attention.self.value.bias\n","bert_layer.encoder.layer.9.attention.output.dense.weight\n","bert_layer.encoder.layer.9.attention.output.dense.bias\n","bert_layer.encoder.layer.9.attention.output.LayerNorm.weight\n","bert_layer.encoder.layer.9.attention.output.LayerNorm.bias\n","bert_layer.encoder.layer.9.intermediate.dense.weight\n","bert_layer.encoder.layer.9.intermediate.dense.bias\n","bert_layer.encoder.layer.9.output.dense.weight\n","bert_layer.encoder.layer.9.output.dense.bias\n","bert_layer.encoder.layer.9.output.LayerNorm.weight\n","bert_layer.encoder.layer.9.output.LayerNorm.bias\n","bert_layer.encoder.layer.10.attention.self.query.weight\n","bert_layer.encoder.layer.10.attention.self.query.bias\n","bert_layer.encoder.layer.10.attention.self.key.weight\n","bert_layer.encoder.layer.10.attention.self.key.bias\n","bert_layer.encoder.layer.10.attention.self.value.weight\n","bert_layer.encoder.layer.10.attention.self.value.bias\n","bert_layer.encoder.layer.10.attention.output.dense.weight\n","bert_layer.encoder.layer.10.attention.output.dense.bias\n","bert_layer.encoder.layer.10.attention.output.LayerNorm.weight\n","bert_layer.encoder.layer.10.attention.output.LayerNorm.bias\n","bert_layer.encoder.layer.10.intermediate.dense.weight\n","bert_layer.encoder.layer.10.intermediate.dense.bias\n","bert_layer.encoder.layer.10.output.dense.weight\n","bert_layer.encoder.layer.10.output.dense.bias\n","bert_layer.encoder.layer.10.output.LayerNorm.weight\n","bert_layer.encoder.layer.10.output.LayerNorm.bias\n","bert_layer.encoder.layer.11.attention.self.query.weight\n","bert_layer.encoder.layer.11.attention.self.query.bias\n","bert_layer.encoder.layer.11.attention.self.key.weight\n","bert_layer.encoder.layer.11.attention.self.key.bias\n","bert_layer.encoder.layer.11.attention.self.value.weight\n","bert_layer.encoder.layer.11.attention.self.value.bias\n","bert_layer.encoder.layer.11.attention.output.dense.weight\n","bert_layer.encoder.layer.11.attention.output.dense.bias\n","bert_layer.encoder.layer.11.attention.output.LayerNorm.weight\n","bert_layer.encoder.layer.11.attention.output.LayerNorm.bias\n","bert_layer.encoder.layer.11.intermediate.dense.weight\n","bert_layer.encoder.layer.11.intermediate.dense.bias\n","bert_layer.encoder.layer.11.output.dense.weight\n","bert_layer.encoder.layer.11.output.dense.bias\n","bert_layer.encoder.layer.11.output.LayerNorm.weight\n","bert_layer.encoder.layer.11.output.LayerNorm.bias\n","bert_layer.pooler.dense.weight\n","bert_layer.pooler.dense.bias\n","linear_layer.weight\n","linear_layer.bias\n"]}],"source":["for name,value in model.named_parameters():\n","    print(name)"]},{"cell_type":"code","execution_count":50,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:05:01.012604Z","iopub.status.busy":"2021-08-18T11:05:01.012266Z","iopub.status.idle":"2021-08-18T11:05:01.850559Z","shell.execute_reply":"2021-08-18T11:05:01.848581Z","shell.execute_reply.started":"2021-08-18T11:05:01.012565Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Parameter containing:\n","tensor([[-0.0005, -0.0416,  0.0131,  ..., -0.0039, -0.0335,  0.0150],\n","        [ 0.0169, -0.0311,  0.0042,  ..., -0.0147, -0.0356, -0.0036],\n","        [-0.0006, -0.0267,  0.0080,  ..., -0.0100, -0.0331, -0.0165],\n","        ...,\n","        [-0.0064,  0.0166, -0.0204,  ..., -0.0418, -0.0492,  0.0042],\n","        [-0.0048, -0.0027, -0.0290,  ..., -0.0512,  0.0045, -0.0118],\n","        [ 0.0313, -0.0297, -0.0230,  ..., -0.0145, -0.0525,  0.0284]],\n","       requires_grad=True)\n"]}],"source":["for i in model.parameters():\n","    print(i)\n","    break"]},{"cell_type":"markdown","metadata":{},"source":["## Training BERT model"]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:05:01.853962Z","iopub.status.busy":"2021-08-18T11:05:01.853620Z","iopub.status.idle":"2021-08-18T11:05:07.440607Z","shell.execute_reply":"2021-08-18T11:05:07.439711Z","shell.execute_reply.started":"2021-08-18T11:05:01.853930Z"},"trusted":true},"outputs":[],"source":["model = model.to(\"cuda\")"]},{"cell_type":"code","execution_count":52,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:05:07.442328Z","iopub.status.busy":"2021-08-18T11:05:07.441977Z","iopub.status.idle":"2021-08-18T11:05:07.455100Z","shell.execute_reply":"2021-08-18T11:05:07.454175Z","shell.execute_reply.started":"2021-08-18T11:05:07.442290Z"},"trusted":true},"outputs":[],"source":["# Whatever model paramaters are provided in params will be updated every time we call optimizer.step().Here we are updating all our model parameters.\n","\n","optimizer = transformers.AdamW(params=model.parameters() , lr=2e-5 , correct_bias=False)\n","\n","total_steps = len(train_DataLoader) * EPOCHS\n","\n","# Create a schedule with a learning rate that decreases linearly from the initial lr set in the optimizer to 0, after a warmup period during which it \n","# increases linearly from 0 to the initial lr set in the optimizer\n","scheduler = transformers.get_linear_schedule_with_warmup(optimizer=optimizer , num_training_steps=total_steps, num_warmup_steps=0)\n","\n","# class_weight = df_train[\"Actual_Sentiment\"].value_counts(normalize=True).sort_index().values\n","# print(class_weight)\n","# loss_function = nn.CrossEntropyLoss(weight=torch.tensor(class_weight,dtype=torch.float32)).to(\"cuda\") \n","\n","loss_function = nn.CrossEntropyLoss().to(\"cuda\") \n","# It also has a weight parameter which can be set in order to deal with class imbalance without oversampling/undersampling.\n","# It works similar to class_weight = \"balanced\" in sklearn-logisticregression.\n","# As weights are inverse of class frequency,We give high weights to minority class and small weights to majority class.\n","# So it assigns large loss if model wrongly predicts minority class ."]},{"cell_type":"code","execution_count":53,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:05:07.456758Z","iopub.status.busy":"2021-08-18T11:05:07.456400Z","iopub.status.idle":"2021-08-18T11:05:07.739299Z","shell.execute_reply":"2021-08-18T11:05:07.738283Z","shell.execute_reply.started":"2021-08-18T11:05:07.456722Z"},"trusted":true},"outputs":[],"source":["def train_one_step(model,optimizer,data,scheduler,loss_function):\n","    \n","    correct_prediction = 0\n","    \n","    optimizer.zero_grad() #Do this at starting of every step.Pytorch dont do it automatically as NN like RNN required gradients to add up over the iterations.\n","    \n","    data['x'] = data['x'].to(\"cuda\")\n","    data['y'] = data['y'].to(\"cuda\")\n","    data['attention_mask'] = data['attention_mask'].to(\"cuda\")\n","        \n","    model_output = model(input_ids=data['x'],attention_mask=data['attention_mask'])\n","    \n","    _,pred = torch.max(model_output , dim=1) # This will return the max value and the position(0,1 or 2).\n","    \n","    loss = loss_function(model_output,data[\"y\"]) # Input: (N, C)where C = number of classes.Check documentation.IMP\n"," \n","    loss.backward() # Calling .backward() mutiple times accumulates the gradient (by addition) for each parameter. This is why you should call optimizer.zero_grad() \n","#     after each .step() call. Note that following the first .backward call, a second call is only possible after you have performed another forward pass.\n","    \n","    nn.utils.clip_grad_norm_(model.parameters() , max_norm=1.0) # Doing gradient cliping to avoid exploading gradient casses.\n","    \n","    optimizer.step()  # optimizer.step performs a parameter update based on the current gradient (stored in .grad attribute of a parameter) and the update rule\n","    \n","    correct_prediction += torch.sum(pred == data[\"y\"])\n","    \n","    accuracy = correct_prediction/len(data['y'])\n","\n","    matthews_coeff = matthews_corrcoef(data['y'].detach().cpu(),pred.detach().cpu())\n","    \n","#     pred_proba = nn.functional.softmax(model_output , dim=1)\n","   \n","#     auc_score = roc_auc_score(data['y'].detach().cpu() , pred_proba.detach().cpu(),multi_class='ovo')\n","        \n","    return loss,accuracy,matthews_coeff\n","   \n","    \n","    "]},{"cell_type":"code","execution_count":54,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:05:07.743306Z","iopub.status.busy":"2021-08-18T11:05:07.743031Z","iopub.status.idle":"2021-08-18T11:05:07.752240Z","shell.execute_reply":"2021-08-18T11:05:07.751513Z","shell.execute_reply.started":"2021-08-18T11:05:07.743279Z"},"trusted":true},"outputs":[],"source":["def train_one_epoch(model,data_loader,optimizer,scheduler,loss_function):\n","    \n","    model.train() # It doesnt train the model,but rather set a flag to let pytorch know that now model is in training phase.\n","#     This is done to make pytorch handle dropout differently during trainig and validation.\n","    total_loss = 0    \n","    total_accuracy = 0\n","    total_matthews_coeff = 0\n","#     total_auc_score = 0\n","    \n","    for batch_index , data in enumerate(data_loader): # If total data in train set is 1000 and our batch_size is 10 so the below loop will run for 100 times/steps.\n","#         And in each step 10 data points will go as input.So train_one_step will get 10 data points at each iteration.\n","        \n","        loss,accuracy,matthews_coeff = train_one_step(model,optimizer,data,scheduler,loss_function)\n","        \n","        scheduler.step()\n","        \n","        total_loss += loss\n","        total_accuracy += accuracy\n","        total_matthews_coeff += matthews_coeff\n","#         total_auc_score += auc_score\n","            \n","    \n","    return total_loss/len(data_loader) , total_accuracy/len(data_loader) , total_matthews_coeff/len(data_loader) "]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:05:07.753922Z","iopub.status.busy":"2021-08-18T11:05:07.753533Z","iopub.status.idle":"2021-08-18T11:05:07.765229Z","shell.execute_reply":"2021-08-18T11:05:07.764296Z","shell.execute_reply.started":"2021-08-18T11:05:07.753885Z"},"trusted":true},"outputs":[],"source":["def val_one_step(model,data,loss_function):\n","    \n","    correct_prediction = 0\n","    \n","    data['x'] = data['x'].to(\"cuda\")\n","    data['y'] = data['y'].to(\"cuda\")\n","    data['attention_mask'] = data['attention_mask'].to(\"cuda\")\n","        \n","    model_output = model(input_ids=data['x'],attention_mask=data['attention_mask'])\n","    \n","    _,pred = torch.max(model_output , dim=1) # This will return the max value and the position(0,1 or 2).\n","    \n","    loss = loss_function(model_output,data[\"y\"])\n","    \n","    correct_prediction += torch.sum(pred == data[\"y\"])\n","    \n","    accuracy = correct_prediction/len(data['y'])\n","    \n","    matthews_coeff = matthews_corrcoef(data['y'].detach().cpu(),pred.detach().cpu())\n","    \n","#     pred_proba = nn.functional.softmax(model_output , dim=1)\n","    \n","#     auc_score = roc_auc_score(data['y'].detach().cpu() , pred_proba.detach().cpu(),multi_class='ovo')\n","    \n","    return loss,accuracy,matthews_coeff"]},{"cell_type":"code","execution_count":56,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:05:07.767070Z","iopub.status.busy":"2021-08-18T11:05:07.766708Z","iopub.status.idle":"2021-08-18T11:05:07.775156Z","shell.execute_reply":"2021-08-18T11:05:07.774214Z","shell.execute_reply.started":"2021-08-18T11:05:07.767034Z"},"trusted":true},"outputs":[],"source":["def val_one_epoch(model,data_loader,loss_function):\n","    \n","    model.eval() # This dont evaluate the model but rather set some flag to make pytorch know that model \n","#     is in evaluation phase now and so pytorch will handle drop out differently now.\n","    \n","    total_loss = 0\n","    total_accuracy = 0\n","    total_matthews_coeff = 0\n","#     total_auc_score = 0\n","    \n","    for batch_index ,data in enumerate(data_loader):\n","        \n","        with torch.no_grad(): # We dont want to update our parameters during validation.\n","            \n","            loss ,accuracy,matthews_coeff = val_one_step(model,data,loss_function)\n","            \n","        total_loss += loss\n","        total_accuracy += accuracy\n","        total_matthews_coeff += matthews_coeff\n","#         total_auc_score += auc_score\n","        \n","    return total_loss/len(data_loader) , total_accuracy/len(data_loader) , total_matthews_coeff/len(data_loader) "]},{"cell_type":"code","execution_count":57,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:05:07.777203Z","iopub.status.busy":"2021-08-18T11:05:07.776688Z","iopub.status.idle":"2021-08-18T11:05:07.791067Z","shell.execute_reply":"2021-08-18T11:05:07.789987Z","shell.execute_reply.started":"2021-08-18T11:05:07.777159Z"},"trusted":true},"outputs":[],"source":["history = defaultdict(list)\n","\n","def train_model():\n","    \n","    global history\n","    best_accuracy = 0\n","\n","    for epoch in range(EPOCHS):\n","\n","        print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n","        print(\"-\"*10)\n","\n","        train_loss,train_accuracy,train_matthews_coeff = train_one_epoch(model,train_DataLoader,optimizer,scheduler,loss_function)\n","        print(f'Train Loss      : {train_loss:.4f} ,   Train Accuracy      : {train_accuracy:.4f}   , Train Matthews Coeff       : {train_matthews_coeff:.4f} ')\n","\n","        val_loss,val_accuracy,val_matthews_coeff = val_one_epoch(model,val_DataLoader,loss_function)\n","        print(f'Validation Loss : {val_loss:.4f} ,   Validation Accuracy : {val_accuracy:.4f}   , Validation Matthews Coeff  : {val_matthews_coeff:.4f} ')\n","\n","        history[\"train_accuracy\"].append(train_accuracy)\n","        history[\"val_accuracy\"].append(val_accuracy)\n","        history[\"train_loss\"].append(train_loss)\n","        history[\"val_loss\"].append(val_loss)\n","        history[\"train_matthews_coeff\"].append(train_matthews_coeff)\n","        history[\"val_matthews_coeff\"].append(val_matthews_coeff)\n","#         history[\"train_auc_score\"].append(train_auc_score)\n","#         history[\"val_auc_score\"].append(val_auc_score)\n","\n","        if val_accuracy > best_accuracy:\n","#             torch.save(model,f\"final_model_{epoch+1}\")\n","            torch.save(model.state_dict(),f\"best_model_{epoch+1}_final.bin\") # In PyTorch, the learnable parameters (i.e. weights and biases) of a torch.nn.Module model are \n","#             contained in the model’s parameters (accessed with model.parameters()). A state_dict is simply a Python dictionary object that maps each layer to its parameter tensor.\n","# A state_dict is an integral entity if you are interested in saving or loading models from PyTorch. Because state_dict objects are Python dictionaries, they can be easily saved, \n","# updated, altered, and restored, adding a great deal of modularity to PyTorch models and optimizers\n","            best_accuracy = val_accuracy\n","            \n","    return best_accuracy"]},{"cell_type":"code","execution_count":58,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:05:07.793334Z","iopub.status.busy":"2021-08-18T11:05:07.792856Z","iopub.status.idle":"2021-08-18T11:14:52.613958Z","shell.execute_reply":"2021-08-18T11:14:52.612973Z","shell.execute_reply.started":"2021-08-18T11:05:07.793272Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Epoch 1/2\n","----------\n","Train Loss      : 0.4221 ,   Train Accuracy      : 0.8392   , Train Matthews Coeff       : 0.7598 \n","Validation Loss : 0.3434 ,   Validation Accuracy : 0.8664   , Validation Matthews Coeff  : 0.8008 \n","\n","Epoch 2/2\n","----------\n","Train Loss      : 0.2161 ,   Train Accuracy      : 0.9312   , Train Matthews Coeff       : 0.8966 \n","Validation Loss : 0.4215 ,   Validation Accuracy : 0.8649   , Validation Matthews Coeff  : 0.7930 \n","CPU times: user 9min 27s, sys: 5.14 s, total: 9min 33s\n","Wall time: 9min 44s\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n","  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"]},{"data":{"text/plain":["tensor(0.8664, device='cuda:0')"]},"execution_count":58,"metadata":{},"output_type":"execute_result"}],"source":["%%time\n","\n","train_model()\n","\n","# As the model's validation loss keeps on increasing after the first epoch,our model is overfitting,\n","# so we will use the model build after the first epoch only."]},{"cell_type":"code","execution_count":59,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:14:52.616145Z","iopub.status.busy":"2021-08-18T11:14:52.615704Z","iopub.status.idle":"2021-08-18T11:14:52.630408Z","shell.execute_reply":"2021-08-18T11:14:52.629526Z","shell.execute_reply.started":"2021-08-18T11:14:52.616066Z"},"trusted":true},"outputs":[{"data":{"text/plain":["defaultdict(list,\n","            {'train_accuracy': [tensor(0.8392, device='cuda:0'),\n","              tensor(0.9312, device='cuda:0')],\n","             'val_accuracy': [tensor(0.8664, device='cuda:0'),\n","              tensor(0.8649, device='cuda:0')],\n","             'train_loss': [tensor(0.4221, device='cuda:0', grad_fn=<DivBackward0>),\n","              tensor(0.2161, device='cuda:0', grad_fn=<DivBackward0>)],\n","             'val_loss': [tensor(0.3434, device='cuda:0'),\n","              tensor(0.4215, device='cuda:0')],\n","             'train_matthews_coeff': [0.7597802685982765, 0.896562765230896],\n","             'val_matthews_coeff': [0.8008121045630516, 0.7930042064075973]})"]},"execution_count":59,"metadata":{},"output_type":"execute_result"}],"source":["history"]},{"cell_type":"markdown","metadata":{},"source":["## Loading the Saved Model"]},{"cell_type":"code","execution_count":60,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:14:52.632009Z","iopub.status.busy":"2021-08-18T11:14:52.631661Z","iopub.status.idle":"2021-08-18T11:14:52.635986Z","shell.execute_reply":"2021-08-18T11:14:52.634979Z","shell.execute_reply.started":"2021-08-18T11:14:52.631974Z"},"trusted":true},"outputs":[],"source":["# final_model = torch.load('./final_model_2')\n","# final_model = final_model.cuda()\n","# final_model"]},{"cell_type":"code","execution_count":61,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:14:52.637663Z","iopub.status.busy":"2021-08-18T11:14:52.637262Z","iopub.status.idle":"2021-08-18T11:14:55.451855Z","shell.execute_reply":"2021-08-18T11:14:55.450973Z","shell.execute_reply.started":"2021-08-18T11:14:52.637625Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["final_model = SentimentModel(3)\n","final_model.load_state_dict(torch.load('./best_model_1_final.bin'))\n","final_model = final_model.cuda()"]},{"cell_type":"code","execution_count":62,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:14:55.455271Z","iopub.status.busy":"2021-08-18T11:14:55.454994Z","iopub.status.idle":"2021-08-18T11:14:55.465353Z","shell.execute_reply":"2021-08-18T11:14:55.464506Z","shell.execute_reply.started":"2021-08-18T11:14:55.455245Z"},"trusted":true},"outputs":[],"source":["def predict(model,data_loader):\n","    \n","    model.eval()\n","    \n","    reviews_text = []\n","    predictions = []\n","    actuals = []\n","    pred_probabilities = []\n","    \n","    with torch.no_grad():\n","        \n","        for data in data_loader:\n","            \n","            data['x'] = data['x'].cuda()\n","            data['y'] = data['y'].cuda()\n","            data['attention_mask'] = data['attention_mask'].cuda()\n","        \n","            model_output = model(input_ids = data['x'] , attention_mask = data['attention_mask'])\n","\n","            _,pred = torch.max(model_output , dim=1) # This will return the max value and the position(0,1 or 2).\n","            \n","            pred_proba = nn.functional.softmax(model_output , dim=1) # Because model output is just after a linear layer.We want to compress it btw 0 and 1.\n","            \n","            predictions.extend(pred)\n","            actuals.extend(data['y'])\n","            reviews_text.extend(data['review_text'])\n","            pred_probabilities.extend(pred_proba)\n","        \n","        # Converting in tensors using stack method and putting into CPU\n","        return reviews_text,torch.stack(predictions).cpu(),torch.stack(actuals).cpu(),torch.stack(pred_probabilities).cpu()\n","    "]},{"cell_type":"code","execution_count":63,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:14:55.467203Z","iopub.status.busy":"2021-08-18T11:14:55.466716Z","iopub.status.idle":"2021-08-18T11:15:01.354548Z","shell.execute_reply":"2021-08-18T11:15:01.353561Z","shell.execute_reply.started":"2021-08-18T11:14:55.467166Z"},"trusted":true},"outputs":[],"source":["reviews,predicted,actuals,pred_proba = predict(final_model,test_DataLoader)"]},{"cell_type":"code","execution_count":64,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:15:01.356545Z","iopub.status.busy":"2021-08-18T11:15:01.356193Z","iopub.status.idle":"2021-08-18T11:15:01.387369Z","shell.execute_reply":"2021-08-18T11:15:01.386132Z","shell.execute_reply.started":"2021-08-18T11:15:01.356512Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy               : 0.840\n","\n","Matthews_Corr_coef     : 0.706\n","\n","AUC Score              : 0.894\n","\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.87      0.87      0.87       697\n","           1       0.32      0.15      0.20       116\n","           2       0.84      0.91      0.88       852\n","\n","    accuracy                           0.84      1665\n","   macro avg       0.68      0.64      0.65      1665\n","weighted avg       0.82      0.84      0.83      1665\n","\n"]}],"source":["accuracy = accuracy_score(actuals,predicted)\n","mathews_coeff = matthews_corrcoef(actuals,predicted)\n","auc_score = roc_auc_score(actuals,pred_proba.cpu(),multi_class=\"ovo\")\n","confusion = confusion_matrix(actuals,predicted)\n","class_report = classification_report(actuals,predicted)\n","\n","print(f\"Accuracy               : {accuracy:.3f}\")\n","print(f\"\\nMatthews_Corr_coef     : {mathews_coeff:.3f}\")\n","print(f\"\\nAUC Score              : {auc_score:.3f}\")\n","\n","print(f'\\n\\n{class_report}')"]},{"cell_type":"code","execution_count":65,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:15:01.389594Z","iopub.status.busy":"2021-08-18T11:15:01.389121Z","iopub.status.idle":"2021-08-18T11:15:01.690234Z","shell.execute_reply":"2021-08-18T11:15:01.689317Z","shell.execute_reply.started":"2021-08-18T11:15:01.389548Z"},"trusted":true},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["def show_confusion_matrix(confusion_matrix):\n","  hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n","  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n","  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=0, ha='right')\n","  plt.ylabel('True Sentiment')\n","  plt.xlabel('\\nPredicted Sentiment');\n","\n","df_cm = pd.DataFrame(confusion, index=[\"Negative\",\"Neutral\",\"Positive\"], columns=[\"Negative\",\"Neutral\",\"Positive\"])\n","show_confusion_matrix(df_cm)"]},{"cell_type":"code","execution_count":66,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:15:01.692125Z","iopub.status.busy":"2021-08-18T11:15:01.691718Z","iopub.status.idle":"2021-08-18T11:15:01.700044Z","shell.execute_reply":"2021-08-18T11:15:01.698957Z","shell.execute_reply.started":"2021-08-18T11:15:01.692082Z"},"trusted":true},"outputs":[],"source":["def get_sentiment(text,model,tokenizer,max_len): \n","        \n","    encoding = tokenizer.encode_plus(text,max_length=max_len,add_special_tokens=True,truncation=True,\n","                                         padding='max_length',return_attention_mask=True,return_token_type_ids=False,return_tensors=\"pt\")\n","\n","    model_output = model(input_ids = encoding['input_ids'] , attention_mask = encoding['attention_mask'])\n","    \n","    prob_ = nn.functional.softmax(model_output,dim=1)\n","    senti = torch.max(prob_,dim=1)[1]\n","    \n","    if senti.item() == 0:\n","        return \"NEGATIVE\",prob_\n","    elif senti.item() == 1:\n","        return \"NEUTRAL\",prob_\n","    else:\n","        return \"POSITIVE\",prob_"]},{"cell_type":"markdown","metadata":{},"source":["**0 = Negative ; \n","1 = Neutral ; \n","2 = Positive**"]},{"cell_type":"code","execution_count":67,"metadata":{"execution":{"iopub.execute_input":"2021-08-18T11:15:01.702408Z","iopub.status.busy":"2021-08-18T11:15:01.701922Z","iopub.status.idle":"2021-08-18T11:15:02.280737Z","shell.execute_reply":"2021-08-18T11:15:02.279593Z","shell.execute_reply.started":"2021-08-18T11:15:01.702366Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Sentiment           : POSITIVE\n","\n","Probabilities score : [0.17684065 0.09756833 0.7255911 ]\n"]}],"source":["text='''aditya is a bad boy and nice from heart and has done lot of good things for humanity. .\n","Aditya has killed a person with gun and dropped bomb across world'''\n","\n","model=final_model.cpu()\n","tokenizer=tokenizer\n","max_len =128\n","\n","senti = get_sentiment(text,model,tokenizer,max_len)\n","print(f'Sentiment           : {senti[0]}')\n","print(f'\\nProbabilities score : {senti[1].detach().numpy()[0]}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"}},"nbformat":4,"nbformat_minor":4}
